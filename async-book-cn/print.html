<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Asynchronous Programming in Rust</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="01_getting_started/01_chapter.html"><strong aria-hidden="true">1.</strong> Getting Started</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="01_getting_started/02_why_async.html"><strong aria-hidden="true">1.1.</strong> Why Async?</a></li><li class="chapter-item expanded "><a href="01_getting_started/03_state_of_async_rust.html"><strong aria-hidden="true">1.2.</strong> The State of Asynchronous Rust</a></li><li class="chapter-item expanded "><a href="01_getting_started/04_async_await_primer.html"><strong aria-hidden="true">1.3.</strong> async/.await Primer</a></li></ol></li><li class="chapter-item expanded "><a href="02_execution/01_chapter.html"><strong aria-hidden="true">2.</strong> Under the Hood: Executing Futures and Tasks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="02_execution/02_future.html"><strong aria-hidden="true">2.1.</strong> The Future Trait</a></li><li class="chapter-item expanded "><a href="02_execution/03_wakeups.html"><strong aria-hidden="true">2.2.</strong> Task Wakeups with Waker</a></li><li class="chapter-item expanded "><a href="02_execution/04_executor.html"><strong aria-hidden="true">2.3.</strong> Applied: Build an Executor</a></li><li class="chapter-item expanded "><a href="02_execution/05_io.html"><strong aria-hidden="true">2.4.</strong> Executors and System IO</a></li></ol></li><li class="chapter-item expanded "><a href="03_async_await/01_chapter.html"><strong aria-hidden="true">3.</strong> async/await</a></li><li class="chapter-item expanded "><a href="04_pinning/01_chapter.html"><strong aria-hidden="true">4.</strong> Pinning</a></li><li class="chapter-item expanded "><a href="05_streams/01_chapter.html"><strong aria-hidden="true">5.</strong> Streams</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="05_streams/02_iteration_and_concurrency.html"><strong aria-hidden="true">5.1.</strong> Iteration and Concurrency</a></li></ol></li><li class="chapter-item expanded "><a href="06_multiple_futures/01_chapter.html"><strong aria-hidden="true">6.</strong> Executing Multiple Futures at a Time</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="06_multiple_futures/02_join.html"><strong aria-hidden="true">6.1.</strong> join!</a></li><li class="chapter-item expanded "><a href="06_multiple_futures/03_select.html"><strong aria-hidden="true">6.2.</strong> select!</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.3.</strong> TODO: Spawning</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.4.</strong> TODO: Cancellation and Timeouts</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.5.</strong> TODO: FuturesUnordered</div></li></ol></li><li class="chapter-item expanded "><a href="07_workarounds/01_chapter.html"><strong aria-hidden="true">7.</strong> Workarounds to Know and Love</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="07_workarounds/02_err_in_async_blocks.html"><strong aria-hidden="true">7.1.</strong> ? in async Blocks</a></li><li class="chapter-item expanded "><a href="07_workarounds/03_send_approximation.html"><strong aria-hidden="true">7.2.</strong> Send Approximation</a></li><li class="chapter-item expanded "><a href="07_workarounds/04_recursion.html"><strong aria-hidden="true">7.3.</strong> Recursion</a></li><li class="chapter-item expanded "><a href="07_workarounds/05_async_in_traits.html"><strong aria-hidden="true">7.4.</strong> async in Traits</a></li></ol></li><li class="chapter-item expanded "><a href="08_ecosystem/00_chapter.html"><strong aria-hidden="true">8.</strong> The Async Ecosystem</a></li><li class="chapter-item expanded "><a href="09_example/00_intro.html"><strong aria-hidden="true">9.</strong> Final Project: HTTP Server</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="09_example/01_running_async_code.html"><strong aria-hidden="true">9.1.</strong> Running Asynchronous Code</a></li><li class="chapter-item expanded "><a href="09_example/02_handling_connections_concurrently.html"><strong aria-hidden="true">9.2.</strong> Handling Connections Concurrently</a></li><li class="chapter-item expanded "><a href="09_example/03_tests.html"><strong aria-hidden="true">9.3.</strong> Testing the Server</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">10.</strong> TODO: I/O</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">10.1.</strong> TODO: AsyncRead and AsyncWrite</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.</strong> TODO: Asynchronous Design Patterns: Solutions and Suggestions</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">11.1.</strong> TODO: Modeling Servers and the Request/Response Pattern</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.2.</strong> TODO: Managing Shared State</div></li></ol></li><li class="chapter-item expanded "><a href="12_appendix/01_translations.html"><strong aria-hidden="true">12.</strong> Appendix: Translations of the Book</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Asynchronous Programming in Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/rust-lang/async-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="开始-getting-started"><a class="header" href="#开始-getting-started">开始 Getting Started</a></h1>
<p>Welcome to Asynchronous Programming in Rust! If you're looking to start writing
asynchronous Rust code, you've come to the right place. Whether you're building
a web server, a database, or an operating system, this book will show you
how to use Rust's asynchronous programming tools to get the most out of your
hardware.</p>
<p class="cn">
欢迎来到 Rust 中的异步编程！ 如果你想开始编写异步 Rust 代码，你来对地方了。 无论您是在构建Web服务器、数据库或操作系统，本书将向您展示如何使用 Rust 的异步编程工具来充分利用你的硬件。
</p>
<h2 id="本书覆盖内容-what-this-book-covers"><a class="header" href="#本书覆盖内容-what-this-book-covers">本书覆盖内容 What This Book Covers</a></h2>
<p>This book aims to be a comprehensive, up-to-date guide to using Rust's async
language features and libraries, appropriate for beginners and old hands alike.</p>
<p class="cn">
本书旨在成为Rust异步编程，全面的、不断更新的语言功能和库的指导书籍，适合初学者和老手。
</p>
<ul>
<li>
<p>The early chapters provide an introduction to async programming in general,
and to Rust's particular take on it.</p>
</li>
<li><p class="cn">前面几章对异步编程做了一般介绍，以及 Rust 为它提供的特殊内容。</p>
</li>
<li>
<p>The middle chapters discuss key utilities and control-flow tools you can use
when writing async code, and describe best-practices for structuring libraries
and applications to maximize performance and reusability.</p>
</li>
<li><p class="cn">中间章节讨论了在编写异步代码时你可以使用的关键实用程序和控制流工具，并描述构建库和应用程序的最佳实践，以最大限度地提高性能和可重用性。</p>
</li>
<li>
<p>The last section of the book covers the broader async ecosystem, and provides
a number of examples of how to accomplish common tasks.</p>
</li>
<li><p class="cn">本书的最后一部分涵盖了更广泛的异步生态系统，并提供了一些如何完成常见任务的示例。</p>
</li>
</ul>
<p>With that out of the way, let's explore the exciting world of Asynchronous
Programming in Rust!</p>
<p class="cn">
说完这些，让我们用 Rust 探索令人兴奋的异步编程世界！
</p><div style="break-before: page; page-break-before: always;"></div><h1 id="why-async"><a class="header" href="#why-async">Why Async?</a></h1>
<p>We all love how Rust empowers us to write fast, safe software.
But how does asynchronous programming fit into this vision?</p>
<p class="cn">
我们都喜欢 Rust 如何使我们能够编写快速、安全的软件。
但是异步编程如何适应这个愿景呢？
</p>
<p>Asynchronous programming, or async for short, is a <em>concurrent programming model</em>
supported by an increasing number of programming languages.
It lets you run a large number of concurrent
tasks on a small number of OS threads, while preserving much of the
look and feel of ordinary synchronous programming, through the
<code>async/await</code> syntax.</p>
<p class="cn">
异步编程，简称异步，是一种_并发编程模型_被越来越多的编程语言所支持。
它可以让你运行大量并发少量操作系统线程上的任务，通过`async/await` 语法，同时保留大部分普通同步编程的观感。
</p>
<h2 id="async-vs-other-concurrency-modelsaync-对比其他并发模型"><a class="header" href="#async-vs-other-concurrency-modelsaync-对比其他并发模型">Async vs other concurrency models(Aync 对比其他并发模型)</a></h2>
<p>Concurrent programming is less mature and &quot;standardized&quot; than
regular, sequential programming. As a result, we express concurrency
differently depending on which concurrent programming model
the language is supporting.</p>
<p class="cn">
并发编程没有那么成熟和“标准化”
定期，顺序编程。 结果，我们表示并发
取决于哪个并发编程模型
语言支持。
</p>
<p>A brief overview of the most popular concurrency models can help
you understand how asynchronous programming fits within the broader
field of concurrent programming:</p>
<p class="cn">
对最流行的并发模型的简要概述可以提供帮助
您了解异步编程如何适应更广泛的
并发编程领域：
</p>
<ul>
<li><strong>OS threads</strong> don't require any changes to the programming model,
which makes it very easy to express concurrency. However, synchronizing
between threads can be difficult, and the performance overhead is large.
Thread pools can mitigate some of these costs, but not enough to support
massive IO-bound workloads.</li>
<li><p class="cn"><b>系统线程</b>不需要对编程模型进行任何更改，
这使得表达并发非常容易。 但是，同步
线程之间可能很困难，并且性能开销很大。
线程池可以减轻其中一些成本，但不足以支持
大量 IO 密集型工作负载。</p>
</li>
<li><strong>Event-driven programming</strong>, in conjunction with <em>callbacks</em>, can be very
performant, but tends to result in a verbose, &quot;non-linear&quot; control flow.
Data flow and error propagation is often hard to follow.</li>
<li><p class="cn"><b>事件驱动编程</b>与 _callbacks_ 一起使用，可以非常
但往往会导致冗长的“非线性”控制流。
数据流和错误传播通常很难跟踪</p>
</li>
<li><strong>Coroutines</strong>, like threads, don't require changes to the programming model,
which makes them easy to use. Like async, they can also support a large
number of tasks. However, they abstract away low-level details that
are important for systems programming and custom runtime implementors.</li>
<li><p class="cn"><b>协程</b>与线程一样，不需要更改编程模型，
这使得它们易于使用。与async一样，它们也可以支持大型
任务数。然而，他们抽象掉了一些低层次的细节
对于系统编程和自定义运行时实现者来说非常重要。</p>
</li>
<li><strong>The actor model</strong> divides all concurrent computation into units called
actors, which communicate through fallible message passing, much like
in distributed systems. The actor model can be efficiently implemented, but it leaves
many practical issues unanswered, such as flow control and retry logic.</li>
<li><p class="cn"><b>角色模型</b>将所有并发计算划分为称为角色的单元，
就像在分布式系统中，通过易出错的信息传递进行交流。参与者模型可以有效地实现，
但是许多实际问题尚未解决，例如流控制和重试逻辑。</p>
</li>
</ul>
<p>In summary, asynchronous programming allows highly performant implementations
that are suitable for low-level languages like Rust, while providing
most of the ergonomic benefits of threads and coroutines.</p>
<p class="cn">
总之，异步编程允许高性能的实现
适用于Rust之类的低级语言，同时提供
线程和协同程序的大部分人机工程学优点。
</p>
<h2 id="async-in-rust-vs-other-languagesrust中async与其他语言的对比"><a class="header" href="#async-in-rust-vs-other-languagesrust中async与其他语言的对比">Async in Rust vs other languages(Rust中Async与其他语言的对比)</a></h2>
<p>Although asynchronous programming is supported in many languages, some
details vary across implementations. Rust's implementation of async
differs from most languages in a few ways:</p>
<p class="cn">
虽然许多语言都支持异步编程，但有些各个实现的详细信息各不相同。
Rust的异步实现与大多数语言在以下几个方面不同：
</p>
<ul>
<li><strong>Futures are inert</strong> in Rust and make progress only when polled. Dropping a
future stops it from making further progress.</li>
<li><p class="cn"><b>Futures是惰性的</b>只有在接受调查后才能取得进展。放弃未来会阻止它取得进一步的进步。</p>
</li>
<li><strong>Async is zero-cost</strong> in Rust, which means that you only pay for what you use.
Specifically, you can use async without heap allocations and dynamic dispatch,
which is great for performance!
This also lets you use async in constrained environments, such as embedded systems.</li>
<li><p class="cn"><b>Async是零开销的</b>在Rust中，这意味着你只需为你使用的东西付费。
具体来说，您可以使用异步，而无需堆分配和动态调度，这对性能非常好！
这还允许您在受限环境（如嵌入式系统）中使用异步。</p>
</li>
<li><strong>No built-in runtime</strong> is provided by Rust. Instead, runtimes are provided by
community maintained crates.</li>
<li><p class="cn">rust语言本身<b>不提供内置的运行时</b>，相反，运行时由社区维护的crates。</p>
</li>
<li><strong>Both single- and multithreaded</strong> runtimes are available in Rust, which have
different strengths and weaknesses.</li>
<li><p class="cn">Rust<b>可同时支持单线程和多线程</b>的运行时，它们有不同的优势和劣势</p>
</li>
</ul>
<h2 id="async-vs-threads-in-rustrust中的async-对比-线程"><a class="header" href="#async-vs-threads-in-rustrust中的async-对比-线程">Async vs threads in Rust(Rust中的Async 对比 线程)</a></h2>
<p>The primary alternative to async in Rust is using OS threads, either
directly through <a href="https://doc.rust-lang.org/std/thread/"><code>std::thread</code></a>
or indirectly through a thread pool.</p>
<p class="cn">
Rust中异步的主要替代方法是使用OS线程，无论是使用<a href="https://doc.rust-lang.org/std/thread/">`std::thread`</a>
或者通过一个线程池。
</p>
<p>Migrating from threads to async or vice versa
typically requires major refactoring work, both in terms of implementation and
(if you are building a library) any exposed public interfaces. As such,
picking the model that suits your needs early can save a lot of development time.</p>
<p class="cn">
从线程迁移到异步或从异步迁移到线程通常需要进行大量重构工作，无论是在实现方面还是在任何公开的公共接口（如果您正在构建库）方面。
因此，尽早选择适合您需要的模型可以节省大量开发时间。
</p>
<p><strong>OS threads</strong> are suitable for a small number of tasks, since threads come with
CPU and memory overhead. Spawning and switching between threads
is quite expensive as even idle threads consume system resources.
A thread pool library can help mitigate some of these costs, but not all.
However, threads let you reuse existing synchronous code without significant
code changes—no particular programming model is required.
In some operating systems, you can also change the priority of a thread,
which is useful for drivers and other latency sensitive applications.</p>
<p class="cn">
<b>系统线程</b>适用于少量任务，因为线程会带来CPU和内存开销。
生成线程和在线程之间切换非常昂贵，因为即使是空闲线程也会消耗系统资源。
线程池库可以帮助降低其中一些成本，但不是全部。
然而，线程允许您重用现有的同步代码，而无需进行重大的代码更改—不需要特定的编程模型。
在某些操作系统中，还可以更改线程的优先级，
这对于驱动程序和其他对延迟敏感的应用程序非常有用。
</p>
<p><strong>Async</strong> provides significantly reduced CPU and memory
overhead, especially for workloads with a
large amount of IO-bound tasks, such as servers and databases.
All else equal, you can have orders of magnitude more tasks than OS threads,
because an async runtime uses a small amount of (expensive) threads to handle
a large amount of (cheap) tasks.
However, async Rust results in larger binary blobs due to the state
machines generated from async functions and since each executable
bundles an async runtime.</p>
<p class="cn">
<b>Async</b>可以显著降低了CPU和内存开销，特别是对于具有大量IO绑定任务的工作负载，如服务器和数据库，
因为异步运行时使用少量（昂贵的）线程来处理大量（廉价的）任务。
然而，Rust的异步会导致更大的二进制blob，主要由于为异步函数生成的状态机以及每个可执行文件需捆绑一个异步运行时。
</p>
<p>On a last note, asynchronous programming is not <em>better</em> than threads,
but different.
If you don't need async for performance reasons, threads can often be
the simpler alternative.</p>
<p class="cn">
最后，异步编程并不比线程更好，
但不同。
如果出于性能原因不需要异步，线程通常是更简单的选择。
</p>
<h3 id="example-concurrent-downloading例子并发下载"><a class="header" href="#example-concurrent-downloading例子并发下载">Example: Concurrent downloading(例子：并发下载)</a></h3>
<p>In this example our goal is to download two web pages concurrently.
In a typical threaded application we need to spawn threads
to achieve concurrency:</p>
<p class="cn">
在本例中，我们的目标是同时下载两个网页。
在典型的线程化应用程序中，我们需要生成线程以实现并发：
</p>
<pre><code class="language-rust ignore">fn get_two_sites() {
    // Spawn two threads to do work.
    let thread_one = thread::spawn(|| download(&quot;https://www.foo.com&quot;));
    let thread_two = thread::spawn(|| download(&quot;https://www.bar.com&quot;));

    // Wait for both threads to complete.
    thread_one.join().expect(&quot;thread one panicked&quot;);
    thread_two.join().expect(&quot;thread two panicked&quot;);
}
</code></pre>
<p>However, downloading a web page is a small task; creating a thread
for such a small amount of work is quite wasteful. For a larger application, it
can easily become a bottleneck. In async Rust, we can run these tasks
concurrently without extra threads:</p>
<p class="cn">
然而，下载网页是一项小任务；为如此少量的工作创建一个线程是非常浪费的。
对于较大的应用程序，它很容易成为瓶颈。在Rust async中，我们可以在没有额外线程的情况下并发运行这些任务：
</p>
<pre><code class="language-rust ignore">async fn get_two_sites_async() {
    // Create two different &quot;futures&quot; which, when run to completion,
    // will asynchronously download the webpages.
    let future_one = download_async(&quot;https://www.foo.com&quot;);
    let future_two = download_async(&quot;https://www.bar.com&quot;);

    // Run both futures to completion at the same time.
    join!(future_one, future_two);
}
</code></pre>
<p>Here, no extra threads are created. Additionally, all function calls are statically
dispatched, and there are no heap allocations!
However, we need to write the code to be asynchronous in the first place,
which this book will help you achieve.</p>
<p class="cn">
在这里，不会创建额外的线程。此外，所有函数调用都是静态调度的，并且没有堆分配！
然而，我们首先需要将代码编写为异步的，这本书将帮助您实现。
</p>
<h2 id="custom-concurrency-models-in-rust在rust中定制并发模型"><a class="header" href="#custom-concurrency-models-in-rust在rust中定制并发模型">Custom concurrency models in Rust(在Rust中定制并发模型)</a></h2>
<p>On a last note, Rust doesn't force you to choose between threads and async.
You can use both models within the same application, which can be
useful when you have mixed threaded and async dependencies.
In fact, you can even use a different concurrency model altogether,
such as event-driven programming, as long as you find a library that
implements it.</p>
<p class="cn">
最后，Rust不会强迫您在线程和异步之间进行选择。
您可以在同一个应用程序中使用这两个模型，当您混合了线程依赖和异步依赖时，这会很有用。
事实上，您甚至可以使用不同的并发模型，
如事件驱动编程，只要找到实现它的库。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-state-of-asynchronous-rustrust异步编程的状态"><a class="header" href="#the-state-of-asynchronous-rustrust异步编程的状态">The State of Asynchronous Rust(Rust异步编程的状态)</a></h1>
<p>Parts of async Rust are supported with the same stability guarantees as
synchronous Rust. Other parts are still maturing and will change
over time. With async Rust, you can expect:</p>
<p class="cn">
async-Rust的部分功能提供与synchronous-Rust相同的稳定性保证。
其他部分仍在稳定中，并将随着时间的推移而变化。对于async Rust，您可以预期：
</p>
<ul>
<li>Outstanding runtime performance for typical concurrent workloads.</li>
<li><p class="cn">典型并发工作负载的出色运行时性能。</p>
</li>
<li>More frequent interaction with advanced language features, such as lifetimes
and pinning.</li>
<li><p class="cn">更频繁地与高级语言功能交互，如生命周期和固定。</p>
</li>
<li>Some compatibility constraints, both between sync and async code, and between
different async runtimes.</li>
<li><p class="cn">同步和异步代码之间以及不同异步运行时之间的一些兼容性约束。</p>
</li>
<li>Higher maintenance burden, due to the ongoing evolution of async runtimes
and language support.</li>
<li><p class="cn">由于异步运行时和语言支持的不断发展，维护负担更高。</p>
</li>
</ul>
<p>In short, async Rust is more difficult to use and can result in a higher
maintenance burden than synchronous Rust,
but gives you best-in-class performance in return.
All areas of async Rust are constantly improving,
so the impact of these issues will wear off over time.</p>
<p class="cn">
简言之，异步Rust比同步Rust更难使用，并可能导致更高的维护负担，
但作为回报，它会为您提供一流的性能。
异步Rust的所有领域都在不断改进，
因此，随着时间的推移，这些问题的影响将逐渐消失。
</p>
<h2 id="language-and-library-support语言和库支持"><a class="header" href="#language-and-library-support语言和库支持">Language and library support(语言和库支持)</a></h2>
<p>While asynchronous programming is supported by Rust itself,
most async applications depend on functionality provided
by community crates.</p>
<p class="cn">
虽然Rust本身支持异步编程，
大多数异步应用程序依赖于社区crates提供的功能。
</p>
<p>As such, you need to rely on a mixture of
language features and library support:</p>
<p class="cn">
因此，您需要同时使用语言功能和库支持：
</p>
<ul>
<li>The most fundamental traits, types and functions, such as the
<a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>Future</code></a> trait
are provided by the standard library.</li>
<li><p class="cn">大部分的基础traits, types 和 functions，例如<a href="https://doc.rust-lang.org/std/future/trait.Future.html">`Future`</a> trait 是由标准库提供的。</p>
</li>
<li>The <code>async/await</code> syntax is supported directly by the Rust compiler.</li>
<li><p class="cn">`async/await`语法是Rust编译器直接支持的。</p>
</li>
<li>Many utility types, macros and functions are provided by the
<a href="https://docs.rs/futures/"><code>futures</code></a> crate. They can be used in any async
Rust application.</li>
<li><p class="cn">许多实用程序类型、宏和函数由<a href="https://docs.rs/futures/">`futures`</a>crate提供的。
它们可以用于任何异步Rust应用程序。</p>
</li>
<li>Execution of async code, IO and task spawning are provided by &quot;async
runtimes&quot;, such as Tokio and async-std. Most async applications, and some
async crates, depend on a specific runtime. See
<a href="01_getting_started/../08_ecosystem/00_chapter.html">&quot;The Async Ecosystem&quot;</a> section for more
details.</li>
<li><p class="cn">异步代码、IO和任务生成的执行由“异步运行时”提供，如Tokio和async-std。
大多数异步应用程序和一些异步crate取决于特定的运行时。
请参考<a href="01_getting_started/../08_ecosystem/00_chapter.html">"The Async Ecosystem"</a>章节了解更多信息</p>
</li>
</ul>
<p>Some language features you may be used to from synchronous Rust are not yet
available in async Rust. Notably, Rust does not let you declare async
functions in traits. Instead, you need to use workarounds to achieve the same
result, which can be more verbose.</p>
<p class="cn">
您可能从synchronous Rust中使用的某些语言功能在async Rust中尚不可用。
值得注意的是，Rust不允许在traits中声明异步函数。相反，您需要使用变通方法来实现相同的结果，这可能会更加冗长。
</p>
<h2 id="compiling-and-debugging编译和调试"><a class="header" href="#compiling-and-debugging编译和调试">Compiling and debugging(编译和调试)</a></h2>
<p>For the most part, compiler- and runtime errors in async Rust work
the same way as they have always done in Rust. There are a few
noteworthy differences:</p>
<p class="cn">
在大多数情况下，异步Rust中的编译器错误和运行时错误的工作方式与它们在Rust中的工作方式相同。
有几个值得注意的区别：
</p>
<h3 id="compilation-errors编译错误"><a class="header" href="#compilation-errors编译错误">Compilation errors(编译错误)</a></h3>
<p>Compilation errors in async Rust conform to the same high standards as
synchronous Rust, but since async Rust often depends on more complex language
features, such as lifetimes and pinning, you may encounter these types of
errors more frequently.</p>
<p class="cn">
async-Rust中的编译错误与synchronous-Rust遵循相同的高标准，
但由于async-Rust通常依赖于更复杂的语言功能，如生存期和固定，
因此您可能会更频繁地遇到这些类型的错误。
</p>
<h3 id="runtime-errors运行时错误"><a class="header" href="#runtime-errors运行时错误">Runtime errors(运行时错误)</a></h3>
<p>Whenever the compiler encounters an async function, it generates a state
machine under the hood. Stack traces in async Rust typically contain details
from these state machines, as well as function calls from
the runtime. As such, interpreting stack traces can be a bit more involved than
it would be in synchronous Rust.</p>
<p class="cn">
每当编译器遇到异步函数时，它都会在后台生成一个状态机。
async Rust中的堆栈跟踪通常包含来自这些状态机的详细信息，以及来自运行时的函数调用。
因此，解释堆栈跟踪可能比在同步Rust中要复杂一些。
</p>
<h3 id="new-failure-modes新的失败模型"><a class="header" href="#new-failure-modes新的失败模型">New failure modes(新的失败模型)</a></h3>
<p>A few novel failure modes are possible in async Rust, for instance
if you call a blocking function from an async context or if you implement
the <code>Future</code> trait incorrectly. Such errors can silently pass both the
compiler and sometimes even unit tests. Having a firm understanding
of the underlying concepts, which this book aims to give you, can help you
avoid these pitfalls.</p>
<p class="cn">
异步信任中可能存在一些新的故障模式，例如，如果您从异步上下文调用阻塞函数，或者如果您错误地实现了“Future”特性。
这样的错误可以悄悄地通过编译器，有时甚至是单元测试。对本书旨在给你的基本概念有一个坚定的理解，可以帮助你避免这些陷阱。
</p>
<h2 id="compatibility-considerations兼容性注意事项"><a class="header" href="#compatibility-considerations兼容性注意事项">Compatibility considerations(兼容性注意事项)</a></h2>
<p>Asynchronous and synchronous code cannot always be combined freely.
For instance, you can't directly call an async function from a sync function.
Sync and async code also tend to promote different design patterns, which can
make it difficult to compose code intended for the different environments.</p>
<p class="cn">
异步和同步代码不能总是自由组合。
例如，您不能直接从同步函数调用异步函数。
同步和异步代码也倾向于促进不同的设计模式，这会使编写针对不同环境的代码变得困难。
</p>
<p>Even async code cannot always be combined freely. Some crates depend on a
specific async runtime to function. If so, it is usually specified in the
crate's dependency list.</p>
<p class="cn">
即使异步代码也不能总是自由组合。有些板条箱依赖于特定的异步运行时来运行。如果是，通常在板条箱的依赖项列表中指定。
</p>
<p>These compatibility issues can limit your options, so make sure to
research which async runtime and what crates you may need early.
Once you have settled in with a runtime, you won't have to worry
much about compatibility.</p>
<p class="cn">
这些兼容性问题可能会限制您的选择，因此请确保尽早研究您可能需要的异步运行时和crate。
一旦您适应了运行时，就不必太担心兼容性。
</p>
<h2 id="performance-characteristics性能特点"><a class="header" href="#performance-characteristics性能特点">Performance characteristics(性能特点)</a></h2>
<p>The performance of async Rust depends on the implementation of the
async runtime you're using.
Even though the runtimes that power async Rust applications are relatively new,
they perform exceptionally well for most practical workloads.</p>
<p class="cn">
async Rust的性能取决于所使用的异步运行时的实现。
尽管为异步Rust应用程序提供动力的运行时相对较新，但它们在大多数实际工作负载中表现得异常出色。
</p>
<p>That said, most of the async ecosystem assumes a <em>multi-threaded</em> runtime.
This makes it difficult to enjoy the theoretical performance benefits
of single-threaded async applications, namely cheaper synchronization.
Another overlooked use-case is <em>latency sensitive tasks</em>, which are
important for drivers, GUI applications and so on. Such tasks depend
on runtime and/or OS support in order to be scheduled appropriately.
You can expect better library support for these use cases in the future.</p>
<p class="cn">
也就是说，大多数异步生态系统都假设有一个多线程运行时。这使得很难享受单线程异步应用程序的理论性能优势，即更便宜的同步。
另一个被忽视的用例是对延迟敏感的任务，它对驱动程序、GUI应用程序等很重要。这些任务取决于运行时和/或操作系统支持，以便进行适当的调度。
您可以期望将来对这些用例提供更好的库支持。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="asyncawait-primer启蒙"><a class="header" href="#asyncawait-primer启蒙"><code>async</code>/<code>.await</code> Primer(启蒙)</a></h1>
<p><code>async</code>/<code>.await</code> is Rust's built-in tool for writing asynchronous functions
that look like synchronous code. <code>async</code> transforms a block of code into a
state machine that implements a trait called <code>Future</code>. Whereas calling a
blocking function in a synchronous method would block the whole thread,
blocked <code>Future</code>s will yield control of the thread, allowing other
<code>Future</code>s to run.</p>
<p class="cn">
`async`/`.await`是Rust的内置工具，用于编写类似同步代码的异步函数。
`async`将代码块转换为实现称为“Future”的trait的状态机。
虽然在同步方法中调用阻塞函数会阻塞整个线程，但阻塞的“Future”将释放对线程的控制，允许其他“Future”运行。
</p>
<p>Let's add some dependencies to the <code>Cargo.toml</code> file:</p>
<p class="cn">
让我们为`Cargo.toml`文件添加一些依赖：
</p>
<pre><code class="language-toml">[dependencies]
futures = &quot;0.3&quot;
</code></pre>
<p>To create an asynchronous function, you can use the <code>async fn</code> syntax:</p>
<p class="cn">
要创建异步函数，可以使用'async fn'语法：
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn do_something() { /* ... */ }
<span class="boring">}
</span></code></pre></pre>
<p>The value returned by <code>async fn</code> is a <code>Future</code>. For anything to happen,
the <code>Future</code> needs to be run on an executor.</p>
<p class="cn">
“async fn”返回的值是“Future”。
为得到执行，“Future”需要在执行器上运行。
</p>
<pre><pre class="playground"><code class="language-rust edition2018">// `block_on` blocks the current thread until the provided future has run to
// completion. Other executors provide more complex behavior, like scheduling
// multiple futures onto the same thread.
use futures::executor::block_on;

async fn hello_world() {
    println!(&quot;hello, world!&quot;);
}

fn main() {
    let future = hello_world(); // Nothing is printed
    block_on(future); // `future` is run and &quot;hello, world!&quot; is printed
}
</code></pre></pre>
<p>Inside an <code>async fn</code>, you can use <code>.await</code> to wait for the completion of
another type that implements the <code>Future</code> trait, such as the output of
another <code>async fn</code>. Unlike <code>block_on</code>, <code>.await</code> doesn't block the current
thread, but instead asynchronously waits for the future to complete, allowing
other tasks to run if the future is currently unable to make progress.</p>
<p class="cn">
在“async fn”中，可以使用“”。wait`等待实现“Future”特性的另一个类型的完成，例如另一个“async fn”的输出。
与“block_on”不同，`.wait`不会阻止当前线程，而是异步等待Future完成，如果Future当前无法取得进展，则允许运行其他任务。
</p>
<p>For example, imagine that we have three <code>async fn</code>: <code>learn_song</code>, <code>sing_song</code>,
and <code>dance</code>:</p>
<p class="cn">
例如，假设我们有三个“async fn”：“learn_song”、“sing_song”和“dance”：
</p>
<pre><code class="language-rust ignore">async fn learn_song() -&gt; Song { /* ... */ }
async fn sing_song(song: Song) { /* ... */ }
async fn dance() { /* ... */ }
</code></pre>
<p>One way to do learn, sing, and dance would be to block on each of these
individually:</p>
<p class="cn">
学习、唱歌和跳舞的一种方法是分别学习以下内容：
</p>
<pre><code class="language-rust ignore">fn main() {
    let song = block_on(learn_song());
    block_on(sing_song(song));
    block_on(dance());
}
</code></pre>
<p>However, we're not giving the best performance possible this way—we're
only ever doing one thing at once! Clearly we have to learn the song before
we can sing it, but it's possible to dance at the same time as learning and
singing the song. To do this, we can create two separate <code>async fn</code> which
can be run concurrently:</p>
<p class="cn">
然而，我们并没有尽可能地提供最好的性能，我们只是一次做一件事！
很明显，我们必须先学这首歌，然后才能唱，但也可以在学唱这首歌的同时跳舞。
为此，我们可以创建两个单独的“async fn”，它们可以同时运行：
</p>
<pre><code class="language-rust ignore">async fn learn_and_sing() {
    // Wait until the song has been learned before singing it.
    // We use `.await` here rather than `block_on` to prevent blocking the
    // thread, which makes it possible to `dance` at the same time.
    let song = learn_song().await;
    sing_song(song).await;
}

async fn async_main() {
    let f1 = learn_and_sing();
    let f2 = dance();

    // `join!` is like `.await` but can wait for multiple futures concurrently.
    // If we're temporarily blocked in the `learn_and_sing` future, the `dance`
    // future will take over the current thread. If `dance` becomes blocked,
    // `learn_and_sing` can take back over. If both futures are blocked, then
    // `async_main` is blocked and will yield to the executor.
    futures::join!(f1, f2);
}

fn main() {
    block_on(async_main());
}
</code></pre>
<p>In this example, learning the song must happen before singing the song, but
both learning and singing can happen at the same time as dancing. If we used
<code>block_on(learn_song())</code> rather than <code>learn_song().await</code> in <code>learn_and_sing</code>,
the thread wouldn't be able to do anything else while <code>learn_song</code> was running.
This would make it impossible to dance at the same time. By <code>.await</code>-ing
the <code>learn_song</code> future, we allow other tasks to take over the current thread
if <code>learn_song</code> is blocked. This makes it possible to run multiple futures
to completion concurrently on the same thread.</p>
<p class="cn">
在本例中，学习歌曲必须在唱歌之前进行，但学习和唱歌可以与跳舞同时进行。
如果我们在`learn_and_sing`中使用 `block_on(learn_song())`而不是`learn_song().wait`等待，
运行`learn_song`时，线程将无法执行任何其他操作。这样就不可能同时跳舞了。
由`.wait`等待`learn_song`的Future，如果`learn_song`被阻止，允许其他任务接管当前线程。
这使得可以在同一线程上同时运行多个Future来完成。
</p><div style="break-before: page; page-break-before: always;"></div><h1 id="under-the-hood-executing-futures-and-tasks执行futures和任务的底层结构"><a class="header" href="#under-the-hood-executing-futures-and-tasks执行futures和任务的底层结构">Under the Hood: Executing <code>Future</code>s and Tasks(执行Futures和任务的底层结构)</a></h1>
<p>In this section, we'll cover the underlying structure of how <code>Future</code>s and
asynchronous tasks are scheduled. If you're only interested in learning
how to write higher-level code that uses existing <code>Future</code> types and aren't
interested in the details of how <code>Future</code> types work, you can skip ahead to
the <code>async</code>/<code>await</code> chapter. However, several of the topics discussed in this
chapter are useful for understanding how <code>async</code>/<code>await</code> code works,
understanding the runtime and performance properties of <code>async</code>/<code>await</code> code,
and building new asynchronous primitives. If you decide to skip this section
now, you may want to bookmark it to revisit in the future.</p>
<p class="cn">
在本节中，我们将介绍`Future`和异步任务是如何调度的底层结构。
如果您只对学习如何编写使用现有“Future”类型的更层代码感兴趣，
而对“Future”类型如何工作的细节不感兴趣，那么可以跳到“async”/“await”一章。
然而，本章中讨论的几个主题对于理解“async”/“await”代码的工作原理、理解“async”/“await”代码的运行时和性能属性以及构建新的异步原语都很有用。
如果您现在决定跳过此部分，您可能希望将其添加为书签，以便将来再次访问。
</p>
<p>Now, with that out of the way, let's talk about the <code>Future</code> trait.</p>
<p class="cn">
现在，让我们来谈谈`Future`特征。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-future-traitfuture特征"><a class="header" href="#the-future-traitfuture特征">The <code>Future</code> Trait(<code>Future</code>特征)</a></h1>
<p>The <code>Future</code> trait is at the center of asynchronous programming in Rust.
A <code>Future</code> is an asynchronous computation that can produce a value
(although that value may be empty, e.g. <code>()</code>). A <em>simplified</em> version of
the future trait might look something like this:</p>
<p class="cn">
`Future`特征是Rust异步编程的核心。
`Future`是一种可以生成值的异步计算（尽管该值可能为空，例如`()`）。
未来特征的简化版本可能如下所示：
</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait SimpleFuture {
    type Output;
    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt;;
}

enum Poll&lt;T&gt; {
    Ready(T),
    Pending,
}
<span class="boring">}
</span></code></pre></pre>
<p>Futures can be advanced by calling the <code>poll</code> function, which will drive the
future as far towards completion as possible. If the future completes, it
returns <code>Poll::Ready(result)</code>. If the future is not able to complete yet, it
returns <code>Poll::Pending</code> and arranges for the <code>wake()</code> function to be called
when the <code>Future</code> is ready to make more progress. When <code>wake()</code> is called, the
executor driving the <code>Future</code> will call <code>poll</code> again so that the <code>Future</code> can
make more progress.</p>
<p class="cn">
可以通过调用“poll”函数来推进Future，这将推动Future尽可能接近完成。
如果future完成，它将返回`Poll::Ready(result)`。
如果future还不能完成，它将返回`Poll::Pending`，并安排在`Future`准备好取得更多进展时调用`wake()`函数。
调用`wake()`时，驱动`Future`的执行器将再次调用“poll”，以便`Future`可以取得更大的进展。
</p>
<p>Without <code>wake()</code>, the executor would have no way of knowing when a particular
future could make progress, and would have to be constantly polling every
future. With <code>wake()</code>, the executor knows exactly which futures are ready to
be <code>poll</code>ed.</p>
<p class="cn">
如果没有`wake()`，执行者将无法知道某个特定的未来何时能够取得进展，并且必须不断轮询每个`Future`。
使用`wake()`，执行者可以准确地知道哪些`Future`可以`poll`(轮询)。
</p>
<p>For example, consider the case where we want to read from a socket that may
or may not have data available already. If there is data, we can read it
in and return <code>Poll::Ready(data)</code>, but if no data is ready, our future is
blocked and can no longer make progress. When no data is available, we
must register <code>wake</code> to be called when data becomes ready on the socket,
which will tell the executor that our future is ready to make progress.
A simple <code>SocketRead</code> future might look something like this:</p>
<p class="cn">
例如，考虑这样一种情况，即我们想要从一个套接字中读取数据，该套接字可能已经有数据可用，也可能没有数据可用。
如果有数据，我们可以读入并返回`Poll::Ready(data)`，但如果没有数据准备就绪，我们的future就会受阻，无法再取得进展。
当没有可用数据时，我们必须注册`wake`，以便在套接字上的数据就绪时调用，这将告诉执行者我们的future已经准备好取得进展。
简单的`SocketRead`future可能是这样的：
</p>
<pre><code class="language-rust ignore">pub struct SocketRead&lt;'a&gt; {
    socket: &amp;'a Socket,
}

impl SimpleFuture for SocketRead&lt;'_&gt; {
    type Output = Vec&lt;u8&gt;;

    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {
        if self.socket.has_data_to_read() {
            // The socket has data -- read it into a buffer and return it.
            Poll::Ready(self.socket.read_buf())
        } else {
            // The socket does not yet have data.
            //
            // Arrange for `wake` to be called once data is available.
            // When data becomes available, `wake` will be called, and the
            // user of this `Future` will know to call `poll` again and
            // receive data.
            self.socket.set_readable_callback(wake);
            Poll::Pending
        }
    }
}
</code></pre>
<p>This model of <code>Future</code>s allows for composing together multiple asynchronous
operations without needing intermediate allocations. Running multiple futures
at once or chaining futures together can be implemented via allocation-free
state machines, like this:</p>
<p class="cn">
这种`Future`模型允许组合多个异步操作，而不需要中间分配。
可以通过无分配状态机实现一次运行多个future或将future链接在一起，如下所示：
</p>
<pre><code class="language-rust ignore">/// A SimpleFuture that runs two other futures to completion concurrently.
///
/// Concurrency is achieved via the fact that calls to `poll` each future
/// may be interleaved, allowing each future to advance itself at its own pace.
pub struct Join&lt;FutureA, FutureB&gt; {
    // Each field may contain a future that should be run to completion.
    // If the future has already completed, the field is set to `None`.
    // This prevents us from polling a future after it has completed, which
    // would violate the contract of the `Future` trait.
    a: Option&lt;FutureA&gt;,
    b: Option&lt;FutureB&gt;,
}

impl&lt;FutureA, FutureB&gt; SimpleFuture for Join&lt;FutureA, FutureB&gt;
where
    FutureA: SimpleFuture&lt;Output = ()&gt;,
    FutureB: SimpleFuture&lt;Output = ()&gt;,
{
    type Output = ();
    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {
        // Attempt to complete future `a`.
        if let Some(a) = &amp;mut self.a {
            if let Poll::Ready(()) = a.poll(wake) {
                self.a.take();
            }
        }

        // Attempt to complete future `b`.
        if let Some(b) = &amp;mut self.b {
            if let Poll::Ready(()) = b.poll(wake) {
                self.b.take();
            }
        }

        if self.a.is_none() &amp;&amp; self.b.is_none() {
            // Both futures have completed -- we can return successfully
            Poll::Ready(())
        } else {
            // One or both futures returned `Poll::Pending` and still have
            // work to do. They will call `wake()` when progress can be made.
            Poll::Pending
        }
    }
}
</code></pre>
<p>This shows how multiple futures can be run simultaneously without needing
separate allocations, allowing for more efficient asynchronous programs.
Similarly, multiple sequential futures can be run one after another, like this:</p>
<p class="cn">
这说明了如何在不需要单独分配的情况下同时运行多个Future，从而实现更高效的异步程序。
类似地，可以一个接一个地运行多个顺序future，如下所示：
</p>
<pre><code class="language-rust ignore">/// A SimpleFuture that runs two futures to completion, one after another.
//
// Note: for the purposes of this simple example, `AndThenFut` assumes both
// the first and second futures are available at creation-time. The real
// `AndThen` combinator allows creating the second future based on the output
// of the first future, like `get_breakfast.and_then(|food| eat(food))`.
pub struct AndThenFut&lt;FutureA, FutureB&gt; {
    first: Option&lt;FutureA&gt;,
    second: FutureB,
}

impl&lt;FutureA, FutureB&gt; SimpleFuture for AndThenFut&lt;FutureA, FutureB&gt;
where
    FutureA: SimpleFuture&lt;Output = ()&gt;,
    FutureB: SimpleFuture&lt;Output = ()&gt;,
{
    type Output = ();
    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {
        if let Some(first) = &amp;mut self.first {
            match first.poll(wake) {
                // We've completed the first future -- remove it and start on
                // the second!
                Poll::Ready(()) =&gt; self.first.take(),
                // We couldn't yet complete the first future.
                Poll::Pending =&gt; return Poll::Pending,
            };
        }
        // Now that the first future is done, attempt to complete the second.
        self.second.poll(wake)
    }
}
</code></pre>
<p>These examples show how the <code>Future</code> trait can be used to express asynchronous
control flow without requiring multiple allocated objects and deeply nested
callbacks. With the basic control-flow out of the way, let's talk about the
real <code>Future</code> trait and how it is different.</p>
<p class="cn">
这些示例展示了如何使用`Future`特性来表示异步控制流，而不需要多个分配的对象和深度嵌套的回调。
随着基本控制流程的结束，让我们来谈谈`Future`特征及其真正的不同之处。
</p>
<pre><code class="language-rust ignore">trait Future {
    type Output;
    fn poll(
        // Note the change from `&amp;mut self` to `Pin&lt;&amp;mut Self&gt;`:
        self: Pin&lt;&amp;mut Self&gt;,
        // and the change from `wake: fn()` to `cx: &amp;mut Context&lt;'_&gt;`:
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Self::Output&gt;;
}
</code></pre>
<p>The first change you'll notice is that our <code>self</code> type is no longer <code>&amp;mut Self</code>,
but has changed to <code>Pin&lt;&amp;mut Self&gt;</code>. We'll talk more about pinning in <a href="02_execution/../04_pinning/01_chapter.html">a later
section</a>, but for now know that it allows us to create futures that
are immovable. Immovable objects can store pointers between their fields,
e.g. <code>struct MyFut { a: i32, ptr_to_a: *const i32 }</code>. Pinning is necessary
to enable async/await.</p>
<p class="cn">
您会注意到的第一个变化是，`self`类型不再是`&mut Self`，而是改为`Pin<&mut Self>`。
我们将在[后面的一节][pinning]中更多地讨论“固定”，但现在要知道，它允许我们创造不可移动的future。
不可移动的对象可以在其字段之间存储指针，例如`struct MyFut { a: i32, ptr_to_a: *const i32 }`。
`Pin`是启用`async/await`所必需的。
</p>
<p>Secondly, <code>wake: fn()</code> has changed to <code>&amp;mut Context&lt;'_&gt;</code>. In <code>SimpleFuture</code>,
we used a call to a function pointer (<code>fn()</code>) to tell the future executor that
the future in question should be polled. However, since <code>fn()</code> is just a
function pointer, it can't store any data about <em>which</em> <code>Future</code> called <code>wake</code>.</p>
<p class="cn">
其次，`wake: fn()`已更改为`&mut Context<'_>`。在`SimpleFuture`中，
我们使用对函数指针(`fn()`)的调用来告诉未来的执行者应该轮询所讨论的`future`。
然而，由于`fn()`只是一个函数指针，因此它不能存储关于是哪个`Future`调用`wake`的任何数据。
</p>
<p>In a real-world scenario, a complex application like a web server may have
thousands of different connections whose wakeups should all be
managed separately. The <code>Context</code> type solves this by providing access to
a value of type <code>Waker</code>, which can be used to wake up a specific task.</p>
<p class="cn">
在真实场景中，像web服务器这样的复杂应用程序可能有数千个不同的连接，这些连接的唤醒都应该单独管理。
`Context`类型通过提供对`Waker`类型值的访问来解决此问题，该值可用于唤醒特定任务。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="task-wakeups-with-waker使用-waker唤醒任务"><a class="header" href="#task-wakeups-with-waker使用-waker唤醒任务">Task Wakeups with <code>Waker</code>(使用 <code>Waker</code>唤醒任务)</a></h1>
<p>It's common that futures aren't able to complete the first time they are
<code>poll</code>ed. When this happens, the future needs to ensure that it is polled
again once it is ready to make more progress. This is done with the <code>Waker</code>
type.</p>
<p class="cn">
future无法在第一次`poll`时完成是很常见的。
当这种情况发生时，future需要确保一旦准备好，就可以再次进行`poll`。
这是通过`Waker`类型完成的。
</p>
<p>Each time a future is polled, it is polled as part of a &quot;task&quot;. Tasks are
the top-level futures that have been submitted to an executor.</p>
<p class="cn">
每次轮询future时，都会将其作为“任务”的一部分进行轮询。任务是提交给执行者的顶级future。
</p>
<p><code>Waker</code> provides a <code>wake()</code> method that can be used to tell the executor that
the associated task should be awoken. When <code>wake()</code> is called, the executor
knows that the task associated with the <code>Waker</code> is ready to make progress, and
its future should be polled again.</p>
<p class="cn">
`Waker`提供了一个`wake()`方法，可以用来告诉执行器应该唤醒关联的任务。
调用`wake()`时，执行器知道与`Waker`关联的任务已准备就绪，应该再次轮询它的future。
</p>
<p><code>Waker</code> also implements <code>clone()</code> so that it can be copied around and stored.</p>
<p class="cn">
`Waker`还实现了`clone()`以便可以对其进行复制和存储。
</p>
<p>Let's try implementing a simple timer future using <code>Waker</code>.</p>
<p class="cn">
让我们尝试使用`Waker`实现一个简单的计时器future。
</p>
<h2 id="applied-build-a-timer应用-构建一个计时器"><a class="header" href="#applied-build-a-timer应用-构建一个计时器">Applied: Build a Timer(应用: 构建一个计时器)</a></h2>
<p>For the sake of the example, we'll just spin up a new thread when the timer
is created, sleep for the required time, and then signal the timer future
when the time window has elapsed.</p>
<p class="cn">
出于示例的考虑，我们将在创建计时器时启动一个新线程，在所需的时间内休眠，然后在时间窗口结束时向计时器发出future信号。
</p>
<p>First, start a new project with <code>cargo new --lib timer_future</code> and add the imports
we'll need to get started to <code>src/lib.rs</code>:</p>
<p class="cn">
首先，用`cargo new --lib timer_future`启动一个新项目，并将开始所需的导入添加到`src/lib.rs`:
</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::{
    future::Future,
    pin::Pin,
    sync::{Arc, Mutex},
    task::{Context, Poll, Waker},
    thread,
    time::Duration,
};
<span class="boring">}
</span></code></pre></pre>
<p>Let's start by defining the future type itself. Our future needs a way for the
thread to communicate that the timer has elapsed and the future should complete.
We'll use a shared <code>Arc&lt;Mutex&lt;..&gt;&gt;</code> value to communicate between the thread and
the future.</p>
<p class="cn">
让我们从定义future类型开始。我们的future需要一种线程通信的方式，即计时器已经过了，future应该完成了。
我们将使用共享的`Arc<Mutex<..>>`在线程与future之间通信。
</p>
<pre><code class="language-rust ignore">pub struct TimerFuture {
    shared_state: Arc&lt;Mutex&lt;SharedState&gt;&gt;,
}

/// Shared state between the future and the waiting thread
struct SharedState {
    /// Whether or not the sleep time has elapsed
    completed: bool,

    /// The waker for the task that `TimerFuture` is running on.
    /// The thread can use this after setting `completed = true` to tell
    /// `TimerFuture`'s task to wake up, see that `completed = true`, and
    /// move forward.
    waker: Option&lt;Waker&gt;,
}
</code></pre>
<p>Now, let's actually write the <code>Future</code> implementation!</p>
<p class="cn">
现在，让我们实际编写`Future`实现！
</p>
<pre><code class="language-rust ignore">impl Future for TimerFuture {
    type Output = ();
    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; {
        // Look at the shared state to see if the timer has already completed.
        let mut shared_state = self.shared_state.lock().unwrap();
        if shared_state.completed {
            Poll::Ready(())
        } else {
            // Set waker so that the thread can wake up the current task
            // when the timer has completed, ensuring that the future is polled
            // again and sees that `completed = true`.
            //
            // It's tempting to do this once rather than repeatedly cloning
            // the waker each time. However, the `TimerFuture` can move between
            // tasks on the executor, which could cause a stale waker pointing
            // to the wrong task, preventing `TimerFuture` from waking up
            // correctly.
            //
            // N.B. it's possible to check for this using the `Waker::will_wake`
            // function, but we omit that here to keep things simple.
            shared_state.waker = Some(cx.waker().clone());
            Poll::Pending
        }
    }
}
</code></pre>
<p>Pretty simple, right? If the thread has set <code>shared_state.completed = true</code>,
we're done! Otherwise, we clone the <code>Waker</code> for the current task and pass it to
<code>shared_state.waker</code> so that the thread can wake the task back up.</p>
<p class="cn">
很简单吧？如果线程已设置`shared_state.completed = true`，我们完成了！
否则，我们将克隆当前任务的`Waker`，并将其传递到`shared_state.waker`以便线程可以将任务唤醒。
</p>
<p>Importantly, we have to update the <code>Waker</code> every time the future is polled
because the future may have moved to a different task with a different
<code>Waker</code>. This will happen when futures are passed around between tasks after
being polled.</p>
<p class="cn">
重要的是，我们必须在每次轮询future时更新`Waker`，因为future可能已移动到具有不同`Waker`的不同任务。
当future在被轮询后在任务之间传递时，就会发生这种情况。
</p>
<p>Finally, we need the API to actually construct the timer and start the thread:</p>
<p class="cn">
最后，我们需要API来实际构造计时器并启动线程：
</p>
<pre><code class="language-rust ignore">impl TimerFuture {
    /// Create a new `TimerFuture` which will complete after the provided
    /// timeout.
    pub fn new(duration: Duration) -&gt; Self {
        let shared_state = Arc::new(Mutex::new(SharedState {
            completed: false,
            waker: None,
        }));

        // Spawn the new thread
        let thread_shared_state = shared_state.clone();
        thread::spawn(move || {
            thread::sleep(duration);
            let mut shared_state = thread_shared_state.lock().unwrap();
            // Signal that the timer has completed and wake up the last
            // task on which the future was polled, if one exists.
            shared_state.completed = true;
            if let Some(waker) = shared_state.waker.take() {
                waker.wake()
            }
        });

        TimerFuture { shared_state }
    }
}
</code></pre>
<p>Woot! That's all we need to build a simple timer future. Now, if only we had
an executor to run the future on...</p>
<p class="cn">
吼吼！这就是我们构建一个简单计时器未来所需的全部内容。现在，我们只差一个执行器来运行future......
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="applied-build-an-executor应用创建一个执行器"><a class="header" href="#applied-build-an-executor应用创建一个执行器">Applied: Build an Executor(应用：创建一个执行器)</a></h1>
<p>Rust's <code>Future</code>s are lazy: they won't do anything unless actively driven to
completion. One way to drive a future to completion is to <code>.await</code> it inside
an <code>async</code> function, but that just pushes the problem one level up: who will
run the futures returned from the top-level <code>async</code> functions? The answer is
that we need a <code>Future</code> executor.</p>
<p class="cn">
Rust的`Future`是惰性的：除非积极完成，否则他们什么都不会做。
推动future实现的一种方法是在“async”函数中通过`.await`等待它，
但这只会将问题推向一个层次：谁将运行从顶级“async”函数返回的future？
答案是我们需要一个“future”的执行器。
</p>
<p><code>Future</code> executors take a set of top-level <code>Future</code>s and run them to completion
by calling <code>poll</code> whenever the <code>Future</code> can make progress. Typically, an
executor will <code>poll</code> a future once to start off. When <code>Future</code>s indicate that
they are ready to make progress by calling <code>wake()</code>, they are placed back
onto a queue and <code>poll</code> is called again, repeating until the <code>Future</code> has
completed.</p>
<p class="cn">
`Future`执行器获取一组顶级`Future`并在它能够取得进展时通过调用“poll轮询”来运行它们直至完成。
通常，执行器会对`Future`进行一次`poll`以开始。
当“Future”通过调用`wake()`指示它们已准备好时，它们将被放回队列中，并再次调用`poll`，直到`Future`完成为止。
</p>
<p>In this section, we'll write our own simple executor capable of running a large
number of top-level futures to completion concurrently.</p>
<p class="cn">
在本节中，我们将编写自己的简单执行器，该执行器能够同时运行大量顶级Future。
</p>
<p>For this example, we depend on the <code>futures</code> crate for the <code>ArcWake</code> trait,
which provides an easy way to construct a <code>Waker</code>. Edit <code>Cargo.toml</code> to add
a new dependency:</p>
<p class="cn">
在本例中，`ArcWake`特征依赖于`futures` crate，它提供了一种构建`Waker`的简单方法。
编辑`Cargo.toml`来添加新的依赖项，请执行以下操作：
</p>
<pre><code class="language-toml">[package]
name = &quot;timer_future&quot;
version = &quot;0.1.0&quot;
authors = [&quot;XYZ Author&quot;]
edition = &quot;2018&quot;

[dependencies]
futures = &quot;0.3&quot;
</code></pre>
<p>Next, we need the following imports at the top of <code>src/main.rs</code>:</p>
<p class="cn">
之后，我们需要在 `src/main.rs`中添加下面的imports
</p>
<pre><code class="language-rust ignore">use {
    futures::{
        future::{BoxFuture, FutureExt},
        task::{waker_ref, ArcWake},
    },
    std::{
        future::Future,
        sync::mpsc::{sync_channel, Receiver, SyncSender},
        sync::{Arc, Mutex},
        task::{Context, Poll},
        time::Duration,
    },
    // The timer we wrote in the previous section:
    timer_future::TimerFuture,
};
</code></pre>
<p>Our executor will work by sending tasks to run over a channel. The executor
will pull events off of the channel and run them. When a task is ready to
do more work (is awoken), it can schedule itself to be polled again by
putting itself back onto the channel.</p>
<p class="cn">
我们的执行器将通过发送任务来运行channel来工作。执行器将从channel中拉出事件并运行它们。
当一个任务准备好做更多的工作时（被唤醒），它可以通过将自己放回channel来安排自己再次被轮询。
</p>
<p>In this design, the executor itself just needs the receiving end of the task
channel. The user will get a sending end so that they can spawn new futures.
Tasks themselves are just futures that can reschedule themselves, so we'll
store them as a future paired with a sender that the task can use to requeue
itself.</p>
<p class="cn">
在本设计中，执行器本身只需要任务channel的接收端。用户将获得一个发送端，这样他们就可以产生新的future。
任务本身就可以重新安排自己的未来，因此我们将它们存储为future，并与任务可以用来重新安排自身的发送者配对。
</p>
<pre><code class="language-rust ignore">/// Task executor that receives tasks off of a channel and runs them.
struct Executor {
    ready_queue: Receiver&lt;Arc&lt;Task&gt;&gt;,
}

/// `Spawner` spawns new futures onto the task channel.
#[derive(Clone)]
struct Spawner {
    task_sender: SyncSender&lt;Arc&lt;Task&gt;&gt;,
}

/// A future that can reschedule itself to be polled by an `Executor`.
struct Task {
    /// In-progress future that should be pushed to completion.
    ///
    /// The `Mutex` is not necessary for correctness, since we only have
    /// one thread executing tasks at once. However, Rust isn't smart
    /// enough to know that `future` is only mutated from one thread,
    /// so we need to use the `Mutex` to prove thread-safety. A production
    /// executor would not need this, and could use `UnsafeCell` instead.
    future: Mutex&lt;Option&lt;BoxFuture&lt;'static, ()&gt;&gt;&gt;,

    /// Handle to place the task itself back onto the task queue.
    task_sender: SyncSender&lt;Arc&lt;Task&gt;&gt;,
}

fn new_executor_and_spawner() -&gt; (Executor, Spawner) {
    // Maximum number of tasks to allow queueing in the channel at once.
    // This is just to make `sync_channel` happy, and wouldn't be present in
    // a real executor.
    const MAX_QUEUED_TASKS: usize = 10_000;
    let (task_sender, ready_queue) = sync_channel(MAX_QUEUED_TASKS);
    (Executor { ready_queue }, Spawner { task_sender })
}
</code></pre>
<p>Let's also add a method to spawner to make it easy to spawn new futures.
This method will take a future type, box it, and create a new <code>Arc&lt;Task&gt;</code> with
it inside which can be enqueued onto the executor.</p>
<p class="cn">
让我们向spawner添加一个方法，以便轻松生成新的future。
此方法将接受一个future类型，将其装箱，并创建一个新的`Arc<Task>`，其中包含该类型，可以将其排入执行器的队列。
</p>
<pre><code class="language-rust ignore">impl Spawner {
    fn spawn(&amp;self, future: impl Future&lt;Output = ()&gt; + 'static + Send) {
        let future = future.boxed();
        let task = Arc::new(Task {
            future: Mutex::new(Some(future)),
            task_sender: self.task_sender.clone(),
        });
        self.task_sender.send(task).expect(&quot;too many tasks queued&quot;);
    }
}
</code></pre>
<p>To poll futures, we'll need to create a <code>Waker</code>.
As discussed in the <a href="02_execution/./03_wakeups.html">task wakeups section</a>, <code>Waker</code>s are responsible
for scheduling a task to be polled again once <code>wake</code> is called. Remember that
<code>Waker</code>s tell the executor exactly which task has become ready, allowing
them to poll just the futures that are ready to make progress. The easiest way
to create a new <code>Waker</code> is by implementing the <code>ArcWake</code> trait and then using
the <code>waker_ref</code> or <code>.into_waker()</code> functions to turn an <code>Arc&lt;impl ArcWake&gt;</code>
into a <code>Waker</code>. Let's implement <code>ArcWake</code> for our tasks to allow them to be
turned into <code>Waker</code>s and awoken:</p>
<p class="cn">
要轮询future，我们需要创建一个`Waker`。如[任务唤醒部分]所述，`Waker`负责安排一个任务，以便在调用 `wake`后再次轮询。
请记住，`Waker`会准确地告诉执行器哪项任务已经准备好，让他们只轮询准备好取得进展的future。
创建新`Waker`的最简单方法是实现`ArcWake`特征，然后使用`waker_ref`或`.into_waker()`函数将`Arc<impl ArcWake>`转换为`Waker`。
让我们为我们的任务实现`ArcWake`，让它们变成`Waker`并可被唤醒：
</p>
<pre><code class="language-rust ignore">impl ArcWake for Task {
    fn wake_by_ref(arc_self: &amp;Arc&lt;Self&gt;) {
        // Implement `wake` by sending this task back onto the task channel
        // so that it will be polled again by the executor.
        let cloned = arc_self.clone();
        arc_self
            .task_sender
            .send(cloned)
            .expect(&quot;too many tasks queued&quot;);
    }
}
</code></pre>
<p>When a <code>Waker</code> is created from an <code>Arc&lt;Task&gt;</code>, calling <code>wake()</code> on it will
cause a copy of the <code>Arc</code> to be sent onto the task channel. Our executor then
needs to pick up the task and poll it. Let's implement that:</p>
<p class="cn">
从`Arc<Task>`创建`Waker`时，对其调用`wake()`，将导致`Arc`的副本发送到任务通道。
然后，我们的执行器需要拿起任务并轮询它。让我们实现这一点：
</p>
<pre><code class="language-rust ignore">impl Executor {
    fn run(&amp;self) {
        while let Ok(task) = self.ready_queue.recv() {
            // Take the future, and if it has not yet completed (is still Some),
            // poll it in an attempt to complete it.
            let mut future_slot = task.future.lock().unwrap();
            if let Some(mut future) = future_slot.take() {
                // Create a `LocalWaker` from the task itself
                let waker = waker_ref(&amp;task);
                let context = &amp;mut Context::from_waker(&amp;*waker);
                // `BoxFuture&lt;T&gt;` is a type alias for
                // `Pin&lt;Box&lt;dyn Future&lt;Output = T&gt; + Send + 'static&gt;&gt;`.
                // We can get a `Pin&lt;&amp;mut dyn Future + Send + 'static&gt;`
                // from it by calling the `Pin::as_mut` method.
                if future.as_mut().poll(context).is_pending() {
                    // We're not done processing the future, so put it
                    // back in its task to be run again in the future.
                    *future_slot = Some(future);
                }
            }
        }
    }
}
</code></pre>
<p>Congratulations! We now have a working futures executor. We can even use it
to run <code>async/.await</code> code and custom futures, such as the <code>TimerFuture</code> we
wrote earlier:</p>
<p class="cn">
祝贺我们现在有一个正在工作的future执行器。我们甚至可以使用它来运行`async/.await`代码和自定义future，
例如我们前面写的`TimerFuture`：
</p>
<pre><code class="language-rust edition2018 ignore">fn main() {
    let (executor, spawner) = new_executor_and_spawner();

    // Spawn a task to print before and after waiting on a timer.
    spawner.spawn(async {
        println!(&quot;howdy!&quot;);
        // Wait for our timer future to complete after two seconds.
        TimerFuture::new(Duration::new(2, 0)).await;
        println!(&quot;done!&quot;);
    });

    // Drop the spawner so that our executor knows it is finished and won't
    // receive more incoming tasks to run.
    drop(spawner);

    // Run the executor until the task queue is empty.
    // This will print &quot;howdy!&quot;, pause, and then print &quot;done!&quot;.
    executor.run();
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="executors-and-system-io执行器和系统io"><a class="header" href="#executors-and-system-io执行器和系统io">Executors and System IO(执行器和系统IO)</a></h1>
<p>In the previous section on <a href="02_execution/./02_future.html">The <code>Future</code> Trait</a>, we discussed this example of
a future that performed an asynchronous read on a socket:</p>
<p class="cn">
在前面的[Future特征]部分中，我们讨论了在套接字上执行异步读取的future示例：
</p>
<pre><code class="language-rust ignore">pub struct SocketRead&lt;'a&gt; {
    socket: &amp;'a Socket,
}

impl SimpleFuture for SocketRead&lt;'_&gt; {
    type Output = Vec&lt;u8&gt;;

    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {
        if self.socket.has_data_to_read() {
            // The socket has data -- read it into a buffer and return it.
            Poll::Ready(self.socket.read_buf())
        } else {
            // The socket does not yet have data.
            //
            // Arrange for `wake` to be called once data is available.
            // When data becomes available, `wake` will be called, and the
            // user of this `Future` will know to call `poll` again and
            // receive data.
            self.socket.set_readable_callback(wake);
            Poll::Pending
        }
    }
}
</code></pre>
<p>This future will read available data on a socket, and if no data is available,
it will yield to the executor, requesting that its task be awoken when the
socket becomes readable again. However, it's not clear from this example how
the <code>Socket</code> type is implemented, and in particular it isn't obvious how the
<code>set_readable_callback</code> function works. How can we arrange for <code>wake()</code>
to be called once the socket becomes readable? One option would be to have
a thread that continually checks whether <code>socket</code> is readable, calling
<code>wake()</code> when appropriate. However, this would be quite inefficient, requiring
a separate thread for each blocked IO future. This would greatly reduce the
efficiency of our async code.</p>
<p class="cn">
此future将读取套接字上的可用数据，如果没有可用数据，它将向执行器屈服，请求在套接字再次变为可读时唤醒其任务。
然而，从这个示例中不清楚“Socket”类型是如何实现的，尤其是`set_readable_callback`函数是如何工作的。
一旦套接字变得可读，我们如何调度调用`wake()`？一种选择是让一个线程不断检查“socket”是否可读，并在适当的时候调用`wake()`。
然而，这将非常低效，需要为每个阻塞的IO Future使用单独的线程。这将大大降低异步代码的效率。
</p>
<p>In practice, this problem is solved through integration with an IO-aware
system blocking primitive, such as <code>epoll</code> on Linux, <code>kqueue</code> on FreeBSD and
Mac OS, IOCP on Windows, and <code>port</code>s on Fuchsia (all of which are exposed
through the cross-platform Rust crate <a href="https://github.com/tokio-rs/mio"><code>mio</code></a>). These primitives all allow
a thread to block on multiple asynchronous IO events, returning once one of
the events completes. In practice, these APIs usually look something like
this:</p>
<p class="cn">
实际上，通过与IO感知系统阻塞原语的集成，可以解决此问题，例如Linux上的“epoll”、FreeBSD和Mac OS上的“kqueue”、Windows上的IOCP和Fuchsia上的“port”（所有这些都是通过跨平台的Rust crate[‘mio’]提供）。这些原语都允许线程阻塞多个异步IO事件，并在其中一个事件完成后返回。实际上，这些API通常如下所示：
</p>
<pre><code class="language-rust ignore">struct IoBlocker {
    /* ... */
}

struct Event {
    // An ID uniquely identifying the event that occurred and was listened for.
    id: usize,

    // A set of signals to wait for, or which occurred.
    signals: Signals,
}

impl IoBlocker {
    /// Create a new collection of asynchronous IO events to block on.
    fn new() -&gt; Self { /* ... */ }

    /// Express an interest in a particular IO event.
    fn add_io_event_interest(
        &amp;self,

        /// The object on which the event will occur
        io_object: &amp;IoObject,

        /// A set of signals that may appear on the `io_object` for
        /// which an event should be triggered, paired with
        /// an ID to give to events that result from this interest.
        event: Event,
    ) { /* ... */ }

    /// Block until one of the events occurs.
    fn block(&amp;self) -&gt; Event { /* ... */ }
}

let mut io_blocker = IoBlocker::new();
io_blocker.add_io_event_interest(
    &amp;socket_1,
    Event { id: 1, signals: READABLE },
);
io_blocker.add_io_event_interest(
    &amp;socket_2,
    Event { id: 2, signals: READABLE | WRITABLE },
);
let event = io_blocker.block();

// prints e.g. &quot;Socket 1 is now READABLE&quot; if socket one became readable.
println!(&quot;Socket {:?} is now {:?}&quot;, event.id, event.signals);
</code></pre>
<p>Futures executors can use these primitives to provide asynchronous IO objects
such as sockets that can configure callbacks to be run when a particular IO
event occurs. In the case of our <code>SocketRead</code> example above, the
<code>Socket::set_readable_callback</code> function might look like the following pseudocode:</p>
<p class="cn">
future执行器可以使用这些原语来提供异步IO对象，例如套接字，这些套接字可以配置回调以在特定IO事件发生时运行。
在上面的“SocketRead”示例中，`Socket::set_readable_callback`函数可能类似于以下伪代码：
</p>
<pre><code class="language-rust ignore">impl Socket {
    fn set_readable_callback(&amp;self, waker: Waker) {
        // `local_executor` is a reference to the local executor.
        // this could be provided at creation of the socket, but in practice
        // many executor implementations pass it down through thread local
        // storage for convenience.
        let local_executor = self.local_executor;

        // Unique ID for this IO object.
        let id = self.id;

        // Store the local waker in the executor's map so that it can be called
        // once the IO event arrives.
        local_executor.event_map.insert(id, waker);
        local_executor.add_io_event_interest(
            &amp;self.socket_file_descriptor,
            Event { id, signals: READABLE },
        );
    }
}
</code></pre>
<p>We can now have just one executor thread which can receive and dispatch any
IO event to the appropriate <code>Waker</code>, which will wake up the corresponding
task, allowing the executor to drive more tasks to completion before returning
to check for more IO events (and the cycle continues...).</p>
<p class="cn">
我们现在可以只有一个执行器线程，它可以接收任何IO事件并将其发送到相应的`Waker`，唤醒相应的任务，
允许执行器在返回检查更多IO事件之前驱动更多任务完成（循环继续…）。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="asyncawait"><a class="header" href="#asyncawait"><code>async</code>/<code>.await</code></a></h1>
<p>In <a href="03_async_await/../01_getting_started/04_async_await_primer.html">the first chapter</a>, we took a brief look at <code>async</code>/<code>.await</code>.
This chapter will discuss <code>async</code>/<code>.await</code> in
greater detail, explaining how it works and how <code>async</code> code differs from
traditional Rust programs.</p>
<p class="cn">
在第一章，我们大概的浏览了`async`/`.await`。
这一章我们将会更详细的讨论`async`/`.await`，解释它的工作原理以及“异步”代码与传统Rust程序的区别。
</p>
<p><code>async</code>/<code>.await</code> are special pieces of Rust syntax that make it possible to
yield control of the current thread rather than blocking, allowing other
code to make progress while waiting on an operation to complete.</p>
<p class="cn">
`async`/`.await`是一种特殊的Rust语法，它可以产生对当前线程的控制，而不是阻塞，从而允许其他代码在等待操作完成的同时取得进展。
</p>
<p>There are two main ways to use <code>async</code>: <code>async fn</code> and <code>async</code> blocks.
Each returns a value that implements the <code>Future</code> trait:</p>
<p class="cn">
使用'async'有两种主要方法：'async fn'和'async'块。
每个返回一个实现`Future`特征的值：
</p>
<pre><code class="language-rust edition2018 ignore">
// `foo()` returns a type that implements `Future&lt;Output = u8&gt;`.
// `foo().await` will result in a value of type `u8`.
async fn foo() -&gt; u8 { 5 }

fn bar() -&gt; impl Future&lt;Output = u8&gt; {
    // This `async` block results in a type that implements
    // `Future&lt;Output = u8&gt;`.
    async {
        let x: u8 = foo().await;
        x + 5
    }
}
</code></pre>
<p>As we saw in the first chapter, <code>async</code> bodies and other futures are lazy:
they do nothing until they are run. The most common way to run a <code>Future</code>
is to <code>.await</code> it. When <code>.await</code> is called on a <code>Future</code>, it will attempt
to run it to completion. If the <code>Future</code> is blocked, it will yield control
of the current thread. When more progress can be made, the <code>Future</code> will be picked
up by the executor and will resume running, allowing the <code>.await</code> to resolve.</p>
<p class="cn">
正如我们在第一章中看到的，`async`包体和其他future是惰性的：它们在运行之前什么都不做。
运行`Future`最常见的方式是`.await`。当在`Future`上调用`.await`，它将尝试运行它直到完成。
如果`Future`被阻止，它将释放对当前线程的控制。当可以取得更多进展时，执行器将选择`Future`，并将恢复运行，已允许`.await`解析。
</p>
<h2 id="async-lifetimes生命周期"><a class="header" href="#async-lifetimes生命周期"><code>async</code> Lifetimes(生命周期)</a></h2>
<p>Unlike traditional functions, <code>async fn</code>s which take references or other
non-<code>'static</code> arguments return a <code>Future</code> which is bounded by the lifetime of
the arguments:</p>
<p class="cn">
与传统函数不同，“async fn”接受引用或其他非`static`参数，返回一个受参数生存期限制的`Future`：
</p>
<pre><code class="language-rust edition2018 ignore">// This function:
async fn foo(x: &amp;u8) -&gt; u8 { *x }

// Is equivalent to this function:
fn foo_expanded&lt;'a&gt;(x: &amp;'a u8) -&gt; impl Future&lt;Output = u8&gt; + 'a {
    async move { *x }
}
</code></pre>
<p>This means that the future returned from an <code>async fn</code> must be <code>.await</code>ed
while its non-<code>'static</code> arguments are still valid. In the common
case of <code>.await</code>ing the future immediately after calling the function
(as in <code>foo(&amp;x).await</code>) this is not an issue. However, if storing the future
or sending it over to another task or thread, this may be an issue.</p>
<p class="cn">
这意味着从“async fn”返回的future，在非`static`参数仍然有效前，必须调用了`.await`。
在常见情况下调用函数后立即调用future的`.await`（如`foo(&x).await`）这不是问题。
但是，如果存储future或将其发送到另一个任务或线程，这可能是一个问题。
</p>
<p>One common workaround for turning an <code>async fn</code> with references-as-arguments
into a <code>'static</code> future is to bundle the arguments with the call to the
<code>async fn</code> inside an <code>async</code> block:</p>
<p class="cn">
将引用作为参数的`async fn`转换为`'static` future的一个常见解决方法是将参数与对“async”块内的“async fn”的调用捆绑在一起：
</p>
<pre><code class="language-rust edition2018 ignore">fn bad() -&gt; impl Future&lt;Output = u8&gt; {
    let x = 5;
    borrow_x(&amp;x) // ERROR: `x` does not live long enough
}

fn good() -&gt; impl Future&lt;Output = u8&gt; {
    async {
        let x = 5;
        borrow_x(&amp;x).await
    }
}
</code></pre>
<p>By moving the argument into the <code>async</code> block, we extend its lifetime to match
that of the <code>Future</code> returned from the call to <code>good</code>.</p>
<p class="cn">
通过将参数移动到“async”块中，我们可以延长其生存期，以匹配调用“good”返回的“Future”的生存期。
</p>
<h2 id="async-move"><a class="header" href="#async-move"><code>async move</code></a></h2>
<p><code>async</code> blocks and closures allow the <code>move</code> keyword, much like normal
closures. An <code>async move</code> block will take ownership of the variables it
references, allowing it to outlive the current scope, but giving up the ability
to share those variables with other code:</p>
<p class="cn">
`async `块和闭包允许使用`move`关键字，这与普通闭包非常相似。
“async move”块将获得其引用的变量的所有权，允许其超出当前范围，但放弃与其他代码共享这些变量的能力：
</p>
<pre><code class="language-rust edition2018 ignore">/// `async` block:
///
/// Multiple different `async` blocks can access the same local variable
/// so long as they're executed within the variable's scope
async fn blocks() {
    let my_string = &quot;foo&quot;.to_string();

    let future_one = async {
        // ...
        println!(&quot;{my_string}&quot;);
    };

    let future_two = async {
        // ...
        println!(&quot;{my_string}&quot;);
    };

    // Run both futures to completion, printing &quot;foo&quot; twice:
    let ((), ()) = futures::join!(future_one, future_two);
}

/// `async move` block:
///
/// Only one `async move` block can access the same captured variable, since
/// captures are moved into the `Future` generated by the `async move` block.
/// However, this allows the `Future` to outlive the original scope of the
/// variable:
fn move_block() -&gt; impl Future&lt;Output = ()&gt; {
    let my_string = &quot;foo&quot;.to_string();
    async move {
        // ...
        println!(&quot;{my_string}&quot;);
    }
}
</code></pre>
<h2 id="awaiting-on-a-multithreaded-executor多线程执行器中的await"><a class="header" href="#awaiting-on-a-multithreaded-executor多线程执行器中的await"><code>.await</code>ing on a Multithreaded Executor(多线程执行器中的<code>.await</code>)</a></h2>
<p>Note that, when using a multithreaded <code>Future</code> executor, a <code>Future</code> may move
between threads, so any variables used in <code>async</code> bodies must be able to travel
between threads, as any <code>.await</code> can potentially result in a switch to a new
thread.</p>
<p class="cn">
请注意，当使用多线程“Future”执行器时，“Future”可能会在线程之间移动，
因此“async”主体中使用的任何变量都必须能够在线程之间移动，就像任何`.await`可能会导致切换到新线程。
</p>
<p>This means that it is not safe to use <code>Rc</code>, <code>&amp;RefCell</code> or any other types
that don't implement the <code>Send</code> trait, including references to types that don't
implement the <code>Sync</code> trait.</p>
<p class="cn">
这意味着使用“Rc”、“RefCell”或任何其他未实现“Send”特性的类型（包括对未实现“Sync”特性的类型的引用）是不安全的。
</p>
<p>(Caveat: it is possible to use these types as long as they aren't in scope
during a call to <code>.await</code>.)</p>
<p class="cn">
（注意：在调用`.await`期间，只要这些类型不在作用域内，就可以使用这些类型。）
</p>
<p>Similarly, it isn't a good idea to hold a traditional non-futures-aware lock
across an <code>.await</code>, as it can cause the threadpool to lock up: one task could
take out a lock, <code>.await</code> and yield to the executor, allowing another task to
attempt to take the lock and cause a deadlock. To avoid this, use the <code>Mutex</code>
in <code>futures::lock</code> rather than the one from <code>std::sync</code>.</p>
<p class="cn">
类似地，持有传统的non-futures-aware的锁也不是一个好主意，因为它可能会导致线程池锁定：
一个任务可以获得锁定，`.await`并向执行器屈服，允许另一个任务尝试获取锁并导致死锁。
要避免这种情况，请使用`futures::lock`中的`Mutex`，而不是`std::sync`中的`Mutex`。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pinning固定"><a class="header" href="#pinning固定">Pinning(固定)</a></h1>
<p>To poll futures, they must be pinned using a special type called
<code>Pin&lt;T&gt;</code>. If you read the explanation of <a href="04_pinning/../02_execution/02_future.html">the <code>Future</code> trait</a> in the
previous section <a href="04_pinning/../02_execution/01_chapter.html">&quot;Executing <code>Future</code>s and Tasks&quot;</a>, you'll recognize
<code>Pin</code> from the <code>self: Pin&lt;&amp;mut Self&gt;</code> in the <code>Future::poll</code> method's definition.
But what does it mean, and why do we need it?</p>
<p class="cn">
要轮询future，他们必须使用特定的称为`Pin<T>`的类型来固定。
如果您阅读上一节[执行`Future`s和任务]中对[`Future`特征]的解释，
您将从`Future::poll`方法定义中的`self: Pin<&mut Self>`中识别`Pin`。
但这意味着什么？我们为什么需要它？
</p>
<h2 id="why-pinning为何要固定"><a class="header" href="#why-pinning为何要固定">Why Pinning(为何要固定)</a></h2>
<p><code>Pin</code> works in tandem with the <code>Unpin</code> marker. Pinning makes it possible
to guarantee that an object implementing <code>!Unpin</code> won't ever be moved. To understand
why this is necessary, we need to remember how <code>async</code>/<code>.await</code> works. Consider
the following code:</p>
<p class="cn">
`Pin`与`Unpin`标记配合使用。固定可以保证对象实现`!Unpin`永远不会被移动。
为了理解为什么这是必要的，我们需要记住`async`/`.await`是如何工作的。考虑以下代码：
</p>
<pre><code class="language-rust edition2018 ignore">let fut_one = /* ... */;
let fut_two = /* ... */;
async move {
    fut_one.await;
    fut_two.await;
}
</code></pre>
<p>Under the hood, this creates an anonymous type that implements <code>Future</code>,
providing a <code>poll</code> method that looks something like this:</p>
<p class="cn">
在后台，这将创建一个实现`Future`的匿名类型，提供一个类似以下内容的`poll`方法：
</p>
<pre><code class="language-rust ignore">// The `Future` type generated by our `async { ... }` block
struct AsyncFuture {
    fut_one: FutOne,
    fut_two: FutTwo,
    state: State,
}

// List of states our `async` block can be in
enum State {
    AwaitingFutOne,
    AwaitingFutTwo,
    Done,
}

impl Future for AsyncFuture {
    type Output = ();

    fn poll(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;()&gt; {
        loop {
            match self.state {
                State::AwaitingFutOne =&gt; match self.fut_one.poll(..) {
                    Poll::Ready(()) =&gt; self.state = State::AwaitingFutTwo,
                    Poll::Pending =&gt; return Poll::Pending,
                }
                State::AwaitingFutTwo =&gt; match self.fut_two.poll(..) {
                    Poll::Ready(()) =&gt; self.state = State::Done,
                    Poll::Pending =&gt; return Poll::Pending,
                }
                State::Done =&gt; return Poll::Ready(()),
            }
        }
    }
}
</code></pre>
<p>When <code>poll</code> is first called, it will poll <code>fut_one</code>. If <code>fut_one</code> can't
complete, <code>AsyncFuture::poll</code> will return. Future calls to <code>poll</code> will pick
up where the previous one left off. This process continues until the future
is able to successfully complete.</p>
<p class="cn">
首次调用`poll`时，它将轮询`fut_one`。如果`fut_one`无法完成，将返回`AsyncFuture::poll`。
以后对`poll`的调用将继续前一个调用的中断。这一过程一直持续到future能够成功完成为止。
</p>
<p>However, what happens if we have an <code>async</code> block that uses references?
For example:</p>
<p class="cn">
然而，如果我们有一个使用引用的`async`块，会发生什么呢？
例如：
</p>
<pre><code class="language-rust edition2018 ignore">async {
    let mut x = [0; 128];
    let read_into_buf_fut = read_into_buf(&amp;mut x);
    read_into_buf_fut.await;
    println!(&quot;{:?}&quot;, x);
}
</code></pre>
<p>What struct does this compile down to?</p>
<p class="cn">
这个编译后到底是什么结构？
</p>
<pre><code class="language-rust ignore">struct ReadIntoBuf&lt;'a&gt; {
    buf: &amp;'a mut [u8], // points to `x` below
}

struct AsyncFuture {
    x: [u8; 128],
    read_into_buf_fut: ReadIntoBuf&lt;'what_lifetime?&gt;,
}
</code></pre>
<p>Here, the <code>ReadIntoBuf</code> future holds a reference into the other field of our
structure, <code>x</code>. However, if <code>AsyncFuture</code> is moved, the location of <code>x</code> will
move as well, invalidating the pointer stored in <code>read_into_buf_fut.buf</code>.</p>
<p class="cn">
这里，`ReadIntoBuf` future引用了我们结构的另一个字段`x`。
但是，如果移动了`AsyncFuture`，则`x`的位置也将移动，从而使存储在`read_into_buf_fut.buf`中的指针无效。
</p>
<p>Pinning futures to a particular spot in memory prevents this problem, making
it safe to create references to values inside an <code>async</code> block.</p>
<p class="cn">
将future固定到内存中的特定位置可以防止此问题，使在`async`块中创建对值的引用是安全的。
</p>
<h2 id="pinning-in-detail固定的细节"><a class="header" href="#pinning-in-detail固定的细节">Pinning in Detail(固定的细节)</a></h2>
<p>Let's try to understand pinning by using an slightly simpler example. The problem we encounter
above is a problem that ultimately boils down to how we handle references in self-referential
types in Rust.</p>
<p class="cn">
让我们用一个稍微简单的例子来理解固定。我们在上面遇到的问题最终归结为我们如何在Rust中处理自引用类型中的引用。
</p>
<p>For now our example will look like this:</p>
<p class="cn">
现在，我们的示例如下所示：
</p>
<pre><code class="language-rust  ignore">#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
}

impl Test {
    fn new(txt: &amp;str) -&gt; Self {
        Test {
            a: String::from(txt),
            b: std::ptr::null(),
        }
    }

    fn init(&amp;mut self) {
        let self_ref: *const String = &amp;self.a;
        self.b = self_ref;
    }

    fn a(&amp;self) -&gt; &amp;str {
        &amp;self.a
    }

    fn b(&amp;self) -&gt; &amp;String {
        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
        unsafe { &amp;*(self.b) }
    }
}
</code></pre>
<p><code>Test</code> provides methods to get a reference to the value of the fields <code>a</code> and <code>b</code>. Since <code>b</code> is a
reference to <code>a</code> we store it as a pointer since the borrowing rules of Rust doesn't allow us to
define this lifetime. We now have what we call a self-referential struct.</p>
<p class="cn">
`Test`提供了获取对字段'a'和'b'的值的引用的方法。由于'b'是对'a'的引用，我们将其存储为指针，因为Rust的借用规则不允许我们定义此生存期。
我们现在有了一个自我参照结构。
</p>
<p>Our example works fine if we don't move any of our data around as you can observe by running
this example:</p>
<p class="cn">
如果我们不移动任何数据，那么我们的示例可以很好地运行，您可以通过运行
此示例：
</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    test1.init();
    let mut test2 = Test::new(&quot;test2&quot;);
    test2.init();

    println!(&quot;a: {}, b: {}&quot;, test1.a(), test1.b());
    println!(&quot;a: {}, b: {}&quot;, test2.a(), test2.b());

}
<span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    // We need an `init` method to actually set our self-reference
</span><span class="boring">    fn init(&amp;mut self) {
</span><span class="boring">        let self_ref: *const String = &amp;self.a;
</span><span class="boring">        self.b = self_ref;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(&amp;self) -&gt; &amp;str {
</span><span class="boring">        &amp;self.a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(&amp;self) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<p>We get what we'd expect:</p>
<p class="cn">
我们得到了我们期望的结果
</p>
<pre><code class="language-rust  ignore">a: test1, b: test1
a: test2, b: test2
</code></pre>
<p>Let's see what happens if we swap <code>test1</code> with <code>test2</code> and thereby move the data:</p>
<p class="cn">
让我们看看如果我们将`test1`与`test2`交换，从而移动数据会发生什么：
</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    test1.init();
    let mut test2 = Test::new(&quot;test2&quot;);
    test2.init();

    println!(&quot;a: {}, b: {}&quot;, test1.a(), test1.b());
    std::mem::swap(&amp;mut test1, &amp;mut test2);
    println!(&quot;a: {}, b: {}&quot;, test2.a(), test2.b());

}
<span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn init(&amp;mut self) {
</span><span class="boring">        let self_ref: *const String = &amp;self.a;
</span><span class="boring">        self.b = self_ref;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(&amp;self) -&gt; &amp;str {
</span><span class="boring">        &amp;self.a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(&amp;self) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<p>Naively, we could think that what we should get a debug print of <code>test1</code> two times like this:</p>
<p class="cn">
天真地，我们可以这样想，我们应该得到两次`test1`的调试打印：
</p>
<pre><code class="language-rust  ignore">a: test1, b: test1
a: test1, b: test1
</code></pre>
<p>But instead we get:</p>
<p class="cn">
然而我们得到了下面的结果：
</p>
<pre><code class="language-rust  ignore">a: test1, b: test1
a: test1, b: test2
</code></pre>
<p>The pointer to <code>test2.b</code> still points to the old location which is inside <code>test1</code>
now. The struct is not self-referential anymore, it holds a pointer to a field
in a different object. That means we can't rely on the lifetime of <code>test2.b</code> to
be tied to the lifetime of <code>test2</code> anymore.</p>
<p class="cn">
指向`test2.b`的指针现在仍然指向'test1'内的旧位置。结构不再是自引用的，它持有指向不同对象中字段的指针。
这意味着我们不能再依赖`test2.b`与'test2'的生存期相绑定。
</p>
<p>If you're still not convinced, this should at least convince you:</p>
<p class="cn">
如果你仍然不相信，下面的例子至少应该让你相信：
</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    test1.init();
    let mut test2 = Test::new(&quot;test2&quot;);
    test2.init();

    println!(&quot;a: {}, b: {}&quot;, test1.a(), test1.b());
    std::mem::swap(&amp;mut test1, &amp;mut test2);
    test1.a = &quot;I've totally changed now!&quot;.to_string();
    println!(&quot;a: {}, b: {}&quot;, test2.a(), test2.b());

}
<span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn init(&amp;mut self) {
</span><span class="boring">        let self_ref: *const String = &amp;self.a;
</span><span class="boring">        self.b = self_ref;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(&amp;self) -&gt; &amp;str {
</span><span class="boring">        &amp;self.a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(&amp;self) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<p>The diagram below can help visualize what's going on:</p>
<p class="cn">
下图有助于直观显示发生的情况：
</p>
<p><strong>Fig 1: Before and after swap</strong>
<img src="04_pinning/../assets/swap_problem.jpg" alt="swap_problem" /></p>
<p>It's easy to get this to show undefined behavior and fail in other spectacular ways as well.</p>
<p class="cn">
很容易让它表现出未定义的行为，并以其他令人吃惊的方式失败。
</p>
<h2 id="pinning-in-practice固定的实践"><a class="header" href="#pinning-in-practice固定的实践">Pinning in Practice(固定的实践)</a></h2>
<p>Let's see how pinning and the <code>Pin</code> type can help us solve this problem.</p>
<p class="cn">
让我们看看pinning和`Pin`类型如何帮助我们解决这个问题。
</p>
<p>The <code>Pin</code> type wraps pointer types, guaranteeing that the values behind the
pointer won't be moved. For example, <code>Pin&lt;&amp;mut T&gt;</code>, <code>Pin&lt;&amp;T&gt;</code>,
<code>Pin&lt;Box&lt;T&gt;&gt;</code> all guarantee that <code>T</code> won't be moved even if <code>T: !Unpin</code>.</p>
<p class="cn">
`Pin`类型包装指针类型，确保指针后面的值不会移动。
例如，`Pin<&mut T>`, `Pin<&T>`, `Pin<Box<T>>`都保证即使`T: !Unpin`，也不会移动'T'。
</p>
<p>Most types don't have a problem being moved. These types implement a trait
called <code>Unpin</code>. Pointers to <code>Unpin</code> types can be freely placed into or taken
out of <code>Pin</code>. For example, <code>u8</code> is <code>Unpin</code>, so <code>Pin&lt;&amp;mut u8&gt;</code> behaves just like
a normal <code>&amp;mut u8</code>.</p>
<p class="cn">
大多数类型在移动时没有问题。这些类型实现了一个称为`Unpin`的特性。
指向`Unpin`类型的指针可以自由放入或取出`Pin`。
例如，`u8`是`Unpin`，因此`Pin<&mut u8>`的行为与普通的`mut u8`一样。
</p>
<p>However, types that can't be moved after they're pinned have a marker called
<code>!Unpin</code>. Futures created by async/await is an example of this.</p>
<p class="cn">
但是，固定后无法移动的类型有一个名为`!Unpin`的标记。async/await创建的future就是一个例子。
</p>
<h3 id="pinning-to-the-stack固定到栈"><a class="header" href="#pinning-to-the-stack固定到栈">Pinning to the Stack(固定到栈)</a></h3>
<p>Back to our example. We can solve our problem by using <code>Pin</code>. Let's take a look at what
our example would look like if we required a pinned pointer instead:</p>
<p class="cn">
回到我们的例子。我们可以用`Pin`来解决我们的问题。让我们看看如果我们需要一个固定指针，我们的示例会是什么样子：
</p>
<pre><code class="language-rust  ignore">use std::pin::Pin;
use std::marker::PhantomPinned;

#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
    _marker: PhantomPinned,
}


impl Test {
    fn new(txt: &amp;str) -&gt; Self {
        Test {
            a: String::from(txt),
            b: std::ptr::null(),
            _marker: PhantomPinned, // This makes our type `!Unpin`
        }
    }

    fn init(self: Pin&lt;&amp;mut Self&gt;) {
        let self_ptr: *const String = &amp;self.a;
        let this = unsafe { self.get_unchecked_mut() };
        this.b = self_ptr;
    }

    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
        &amp;self.get_ref().a
    }

    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
        unsafe { &amp;*(self.b) }
    }
}
</code></pre>
<p>Pinning an object to the stack will always be <code>unsafe</code> if our type implements
<code>!Unpin</code>. You can use a crate like <a href="https://docs.rs/pin-utils/"><code>pin_utils</code></a> to avoid writing
our own <code>unsafe</code> code when pinning to the stack.</p>
<p class="cn">
如果我们的类型实现了`!Unpin`，那么将对象固定到堆栈总是`unsafe`的。
您可以使用类似[`pin_utils`][pin_utils]的板条箱，以避免在固定到堆栈时编写我们自己的`不安全`代码。
</p>
<p>Below, we pin the objects <code>test1</code> and <code>test2</code> to the stack:</p>
<p class="cn">
下面，我们将对象`test1`和`test2`固定到堆栈中：
</p>
<pre><pre class="playground"><code class="language-rust">pub fn main() {
    // test1 is safe to move before we initialize it
    let mut test1 = Test::new(&quot;test1&quot;);
    // Notice how we shadow `test1` to prevent it from being accessed again
    let mut test1 = unsafe { Pin::new_unchecked(&amp;mut test1) };
    Test::init(test1.as_mut());

    let mut test2 = Test::new(&quot;test2&quot;);
    let mut test2 = unsafe { Pin::new_unchecked(&amp;mut test2) };
    Test::init(test2.as_mut());

    println!(&quot;a: {}, b: {}&quot;, Test::a(test1.as_ref()), Test::b(test1.as_ref()));
    println!(&quot;a: {}, b: {}&quot;, Test::a(test2.as_ref()), Test::b(test2.as_ref()));
}
<span class="boring">use std::pin::Pin;
</span><span class="boring">use std::marker::PhantomPinned;
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">    _marker: PhantomPinned,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">            // This makes our type `!Unpin`
</span><span class="boring">            _marker: PhantomPinned,
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn init(self: Pin&lt;&amp;mut Self&gt;) {
</span><span class="boring">        let self_ptr: *const String = &amp;self.a;
</span><span class="boring">        let this = unsafe { self.get_unchecked_mut() };
</span><span class="boring">        this.b = self_ptr;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
</span><span class="boring">        &amp;self.get_ref().a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<p>Now, if we try to move our data now we get a compilation error:</p>
<p class="cn">
现在，如果我们现在尝试移动数据，就会出现编译错误：
</p>
<pre><pre class="playground"><code class="language-rust  compile_fail">pub fn main() {
    let mut test1 = Test::new(&quot;test1&quot;);
    let mut test1 = unsafe { Pin::new_unchecked(&amp;mut test1) };
    Test::init(test1.as_mut());

    let mut test2 = Test::new(&quot;test2&quot;);
    let mut test2 = unsafe { Pin::new_unchecked(&amp;mut test2) };
    Test::init(test2.as_mut());

    println!(&quot;a: {}, b: {}&quot;, Test::a(test1.as_ref()), Test::b(test1.as_ref()));
    std::mem::swap(test1.get_mut(), test2.get_mut());
    println!(&quot;a: {}, b: {}&quot;, Test::a(test2.as_ref()), Test::b(test2.as_ref()));
}
<span class="boring">use std::pin::Pin;
</span><span class="boring">use std::marker::PhantomPinned;
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">    _marker: PhantomPinned,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">            _marker: PhantomPinned, // This makes our type `!Unpin`
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn init(self: Pin&lt;&amp;mut Self&gt;) {
</span><span class="boring">        let self_ptr: *const String = &amp;self.a;
</span><span class="boring">        let this = unsafe { self.get_unchecked_mut() };
</span><span class="boring">        this.b = self_ptr;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
</span><span class="boring">        &amp;self.get_ref().a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
<p>The type system prevents us from moving the data.</p>
<p class="cn">
类型系统阻止我们移动数据。
</p>
<blockquote>
<p>It's important to note that stack pinning will always rely on guarantees
you give when writing <code>unsafe</code>. While we know that the <em>pointee</em> of <code>&amp;'a mut T</code>
is pinned for the lifetime of <code>'a</code> we can't know if the data <code>&amp;'a mut T</code>
points to isn't moved after <code>'a</code> ends. If it does it will violate the Pin
contract.</p>
<p class="cn">需要注意的是，堆栈固定始终依赖于您在编写`unsafe`时提供的保证。虽然我们知道`&'a mut T`的指针对象在`'a`的生存期内是固定的，但我们不知道`&'a mut T`指向的数据在`'a`结束后是否没有移动。如果这样做，将违反Pin合约。</p>
<p>A mistake that is easy to make is forgetting to shadow the original variable
since you could drop the <code>Pin</code> and move the data after <code>&amp;'a mut T</code>
like shown below (which violates the Pin contract):</p>
<p class="cn">容易犯的一个错误是忘记隐藏原始变量，因为您可以删除`Pin`并将数据移动到`&'a mut T`之后，如下图所示（这违反了Pin约定）：</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
   let mut test1 = Test::new(&quot;test1&quot;);
   let mut test1_pin = unsafe { Pin::new_unchecked(&amp;mut test1) };
   Test::init(test1_pin.as_mut());

   drop(test1_pin);
   println!(r#&quot;test1.b points to &quot;test1&quot;: {:?}...&quot;#, test1.b);

   let mut test2 = Test::new(&quot;test2&quot;);
   mem::swap(&amp;mut test1, &amp;mut test2);
   println!(&quot;... and now it points nowhere: {:?}&quot;, test1.b);
}
<span class="boring">use std::pin::Pin;
</span><span class="boring">use std::marker::PhantomPinned;
</span><span class="boring">use std::mem;
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">struct Test {
</span><span class="boring">    a: String,
</span><span class="boring">    b: *const String,
</span><span class="boring">    _marker: PhantomPinned,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">impl Test {
</span><span class="boring">    fn new(txt: &amp;str) -&gt; Self {
</span><span class="boring">        Test {
</span><span class="boring">            a: String::from(txt),
</span><span class="boring">            b: std::ptr::null(),
</span><span class="boring">            // This makes our type `!Unpin`
</span><span class="boring">            _marker: PhantomPinned,
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn init&lt;'a&gt;(self: Pin&lt;&amp;'a mut Self&gt;) {
</span><span class="boring">        let self_ptr: *const String = &amp;self.a;
</span><span class="boring">        let this = unsafe { self.get_unchecked_mut() };
</span><span class="boring">        this.b = self_ptr;
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn a&lt;'a&gt;(self: Pin&lt;&amp;'a Self&gt;) -&gt; &amp;'a str {
</span><span class="boring">        &amp;self.get_ref().a
</span><span class="boring">    }
</span><span class="boring">
</span><span class="boring">    fn b&lt;'a&gt;(self: Pin&lt;&amp;'a Self&gt;) -&gt; &amp;'a String {
</span><span class="boring">        assert!(!self.b.is_null(), &quot;Test::b called without Test::init being called first&quot;);
</span><span class="boring">        unsafe { &amp;*(self.b) }
</span><span class="boring">    }
</span><span class="boring">}
</span></code></pre></pre>
</blockquote>
<h3 id="pinning-to-the-heap固定到堆"><a class="header" href="#pinning-to-the-heap固定到堆">Pinning to the Heap(固定到堆)</a></h3>
<p>Pinning an <code>!Unpin</code> type to the heap gives our data a stable address so we know
that the data we point to can't move after it's pinned. In contrast to stack
pinning, we know that the data will be pinned for the lifetime of the object.</p>
<p class="cn">
固定一个`!Unpin`类型为堆提供了一个稳定的地址，因此我们知道所指向的数据在被固定后无法移动。
与栈固定不同，我们知道数据将在对象的生存期内固定。
</p>
<pre><pre class="playground"><code class="language-rust  edition2018">use std::pin::Pin;
use std::marker::PhantomPinned;

#[derive(Debug)]
struct Test {
    a: String,
    b: *const String,
    _marker: PhantomPinned,
}

impl Test {
    fn new(txt: &amp;str) -&gt; Pin&lt;Box&lt;Self&gt;&gt; {
        let t = Test {
            a: String::from(txt),
            b: std::ptr::null(),
            _marker: PhantomPinned,
        };
        let mut boxed = Box::pin(t);
        let self_ptr: *const String = &amp;boxed.as_ref().a;
        unsafe { boxed.as_mut().get_unchecked_mut().b = self_ptr };

        boxed
    }

    fn a(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;str {
        &amp;self.get_ref().a
    }

    fn b(self: Pin&lt;&amp;Self&gt;) -&gt; &amp;String {
        unsafe { &amp;*(self.b) }
    }
}

pub fn main() {
    let test1 = Test::new(&quot;test1&quot;);
    let test2 = Test::new(&quot;test2&quot;);

    println!(&quot;a: {}, b: {}&quot;,test1.as_ref().a(), test1.as_ref().b());
    println!(&quot;a: {}, b: {}&quot;,test2.as_ref().a(), test2.as_ref().b());
}
</code></pre></pre>
<p>Some functions require the futures they work with to be <code>Unpin</code>. To use a
<code>Future</code> or <code>Stream</code> that isn't <code>Unpin</code> with a function that requires
<code>Unpin</code> types, you'll first have to pin the value using either
<code>Box::pin</code> (to create a <code>Pin&lt;Box&lt;T&gt;&gt;</code>) or the <code>pin_utils::pin_mut!</code> macro
(to create a <code>Pin&lt;&amp;mut T&gt;</code>). <code>Pin&lt;Box&lt;Fut&gt;&gt;</code> and <code>Pin&lt;&amp;mut Fut&gt;</code> can both be
used as futures, and both implement <code>Unpin</code>.</p>
<p class="cn">
有些函数要求它们使用的future是`Unpin`。要将非`Unpin`的`Future`或`Stream`与需要`Unpin`类型的函数一起使用，
首先必须使用`Box::pin`（创建``Pin<Box<T>>`）或`pin_utils::pin_mut!`宏（创建`Pin<&mut T>`）。
`Pin<Box<Fut>>` 和 `Pin<&mut Fut>`都可以用作future，并且都实现了`Unpin`。
</p>
<p>For example:</p>
<pre><code class="language-rust edition2018 ignore">use pin_utils::pin_mut; // `pin_utils` is a handy crate available on crates.io

// A function which takes a `Future` that implements `Unpin`.
fn execute_unpin_future(x: impl Future&lt;Output = ()&gt; + Unpin) { /* ... */ }

let fut = async { /* ... */ };
execute_unpin_future(fut); // Error: `fut` does not implement `Unpin` trait

// Pinning with `Box`:
let fut = async { /* ... */ };
let fut = Box::pin(fut);
execute_unpin_future(fut); // OK

// Pinning with `pin_mut!`:
let fut = async { /* ... */ };
pin_mut!(fut);
execute_unpin_future(fut); // OK
</code></pre>
<h2 id="summary总结"><a class="header" href="#summary总结">Summary(总结)</a></h2>
<ol>
<li>
<p>If <code>T: Unpin</code> (which is the default), then <code>Pin&lt;'a, T&gt;</code> is entirely
equivalent to <code>&amp;'a mut T</code>. in other words: <code>Unpin</code> means it's OK for this type
to be moved even when pinned, so <code>Pin</code> will have no effect on such a type.</p>
</li>
<li><p class="cn">如果`T: Unpin`（默认设置），那么`Pin<'a, T>`完全等同于`&'a mut T`。换言之：`Unpin`表示即使在固定时也可以移动此类型，因此`Pin`对此类类型没有影响。</p>
</li>
<li>
<p>Getting a <code>&amp;mut T</code> to a pinned T requires unsafe if <code>T: !Unpin</code>.</p>
</li>
<li><p class="cn">要使`&mut T`成为固定的T，如果`T: !Unpin`需要不安全代码。</p>
</li>
<li>
<p>Most standard library types implement <code>Unpin</code>. The same goes for most
&quot;normal&quot; types you encounter in Rust. A <code>Future</code> generated by async/await is an exception to this rule.</p>
</li>
<li><p class="cn">大多数标准库类型都实现`Unpin`。你在Rust中遇到的大多数`正常`类型也是如此。由async/await生成的`Future`是此规则的一个例外。</p>
</li>
<li>
<p>You can add a <code>!Unpin</code> bound on a type on nightly with a feature flag, or
by adding <code>std::marker::PhantomPinned</code> to your type on stable.</p>
</li>
<li><p class="cn">在nightly版本中使用特性flag，您可以在类型上添加`!Unpin`，或者在stable版本上的类型中添加`std::marker::PhantomPinned`。</p>
</li>
<li>
<p>You can either pin data to the stack or to the heap.</p>
</li>
<li><p class="cn">您可以将数据固定到栈或堆。</p>
</li>
<li>
<p>Pinning a <code>!Unpin</code> object to the stack requires <code>unsafe</code></p>
</li>
<li><p class="cn">固定一个`!Unpin`对象到栈需要`unsafe`代码</p>
</li>
<li>
<p>Pinning a <code>!Unpin</code> object to the heap does not require <code>unsafe</code>. There is a shortcut for doing this using <code>Box::pin</code>.</p>
</li>
<li><p class="cn">固定一个`!Unpin`对象到堆不需要`unsafe`代码。有一个进行此操作的快捷方式，即使用`Box::pin`。</p>
</li>
<li>
<p>For pinned data where <code>T: !Unpin</code> you have to maintain the invariant that its memory will not
get invalidated or repurposed <em>from the moment it gets pinned until when drop</em> is called. This is
an important part of the <em>pin contract</em>.</p>
</li>
<li><p class="cn">对于固定数据，其中`T: !Unpin`您必须保持不变量，使其内存<i>从被固定的那一刻起直到调用drop时</i>都不会失效或重新调整用途。这就是<i>pin合约</i>的一个重要部分。</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-stream-traitstream特征"><a class="header" href="#the-stream-traitstream特征">The <code>Stream</code> Trait(<code>Stream</code>特征)</a></h1>
<p>The <code>Stream</code> trait is similar to <code>Future</code> but can yield multiple values before
completing, similar to the <code>Iterator</code> trait from the standard library:</p>
<p class="cn">
`Stream`特征类似于`Future`，但在完成之前可以生成多个值，类似于标准库中的`Iterator`特征：
</p>
<pre><code class="language-rust ignore">trait Stream {
    /// The type of the value yielded by the stream.
    type Item;

    /// Attempt to resolve the next item in the stream.
    /// Returns `Poll::Pending` if not ready, `Poll::Ready(Some(x))` if a value
    /// is ready, and `Poll::Ready(None)` if the stream has completed.
    fn poll_next(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)
        -&gt; Poll&lt;Option&lt;Self::Item&gt;&gt;;
}
</code></pre>
<p>One common example of a <code>Stream</code> is the <code>Receiver</code> for the channel type from
the <code>futures</code> crate. It will yield <code>Some(val)</code> every time a value is sent
from the <code>Sender</code> end, and will yield <code>None</code> once the <code>Sender</code> has been
dropped and all pending messages have been received:</p>
<p class="cn">
`Stream`的一个常见示例是来自`futures`板条箱的通道类型的`Receiver`。
每次从`Sender`端发送值时，它都会生成`Some(val)`，一旦删除`Sender`并接收到所有挂起的消息，它将生成`None`：
</p>
<pre><code class="language-rust edition2018 ignore">async fn send_recv() {
    const BUFFER_SIZE: usize = 10;
    let (mut tx, mut rx) = mpsc::channel::&lt;i32&gt;(BUFFER_SIZE);

    tx.send(1).await.unwrap();
    tx.send(2).await.unwrap();
    drop(tx);

    // `StreamExt::next` is similar to `Iterator::next`, but returns a
    // type that implements `Future&lt;Output = Option&lt;T&gt;&gt;`.
    assert_eq!(Some(1), rx.next().await);
    assert_eq!(Some(2), rx.next().await);
    assert_eq!(None, rx.next().await);
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="iteration-and-concurrency迭代和并发"><a class="header" href="#iteration-and-concurrency迭代和并发">Iteration and Concurrency(迭代和并发)</a></h1>
<p>Similar to synchronous <code>Iterator</code>s, there are many different ways to iterate
over and process the values in a <code>Stream</code>. There are combinator-style methods
such as <code>map</code>, <code>filter</code>, and <code>fold</code>, and their early-exit-on-error cousins
<code>try_map</code>, <code>try_filter</code>, and <code>try_fold</code>.</p>
<p class="cn">
与同步迭代器类似，有许多不同的方法可以迭代和处理`Stream`中的值。
有诸如`map`、`filter`和`fold`之类的组合式方法，以及它们的异常快速退出版本`try_map`、`try_filter`和`try_fold`。
</p>
<p>Unfortunately, <code>for</code> loops are not usable with <code>Stream</code>s, but for
imperative-style code, <code>while let</code> and the <code>next</code>/<code>try_next</code> functions can
be used:</p>
<p class="cn">
遗憾的是，`for`循环不能用于`Stream`，但对于命令式代码，`while let`和`next`/`try_next`函数可以使用：
</p>
<pre><code class="language-rust edition2018 ignore">async fn sum_with_next(mut stream: Pin&lt;&amp;mut dyn Stream&lt;Item = i32&gt;&gt;) -&gt; i32 {
    use futures::stream::StreamExt; // for `next`
    let mut sum = 0;
    while let Some(item) = stream.next().await {
        sum += item;
    }
    sum
}

async fn sum_with_try_next(
    mut stream: Pin&lt;&amp;mut dyn Stream&lt;Item = Result&lt;i32, io::Error&gt;&gt;&gt;,
) -&gt; Result&lt;i32, io::Error&gt; {
    use futures::stream::TryStreamExt; // for `try_next`
    let mut sum = 0;
    while let Some(item) = stream.try_next().await? {
        sum += item;
    }
    Ok(sum)
}
</code></pre>
<p>However, if we're just processing one element at a time, we're potentially
leaving behind opportunity for concurrency, which is, after all, why we're
writing async code in the first place. To process multiple items from a stream
concurrently, use the <code>for_each_concurrent</code> and <code>try_for_each_concurrent</code>
methods:</p>
<p class="cn">
然而，如果我们一次只处理一个元素，那么就可能会留下并发的机会，毕竟，这就是为什么我们首先要编写异步代码的原因。
要同时处理流中的多个项目，请使用`for_each_concurrent`和`try_for_each_concurrent`方法：
</p>
<pre><code class="language-rust edition2018 ignore">async fn jump_around(
    mut stream: Pin&lt;&amp;mut dyn Stream&lt;Item = Result&lt;u8, io::Error&gt;&gt;&gt;,
) -&gt; Result&lt;(), io::Error&gt; {
    use futures::stream::TryStreamExt; // for `try_for_each_concurrent`
    const MAX_CONCURRENT_JUMPERS: usize = 100;

    stream.try_for_each_concurrent(MAX_CONCURRENT_JUMPERS, |num| async move {
        jump_n_times(num).await?;
        report_n_jumps(num).await?;
        Ok(())
    }).await?;

    Ok(())
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="executing-multiple-futures-at-a-time同时执行多个future"><a class="header" href="#executing-multiple-futures-at-a-time同时执行多个future">Executing Multiple Futures at a Time(同时执行多个future)</a></h1>
<p>Up until now, we've mostly executed futures by using <code>.await</code>, which blocks
the current task until a particular <code>Future</code> completes. However, real
asynchronous applications often need to execute several different
operations concurrently.</p>
<p class="cn">
到目前为止，我们主要通过使`.await`来执行future，它阻止当前任务，直到特定的“Future”完成。
然而，真正的异步应用程序通常需要同时执行几个不同的操作。
</p>
<p>In this chapter, we'll cover some ways to execute multiple asynchronous
operations at the same time:</p>
<p class="cn">
在这一章，我们将会覆盖一些同时执行多个异步操作的一些方式
</p>
<ul>
<li><code>join!</code>: waits for futures to all complete</li>
<li><p class="cn">`join!`: 等待所有future执行完成</p>
</li>
<li><code>select!</code>: waits for one of several futures to complete</li>
<li><p class="cn">`select!`: 等待多个future的一个执行完成</p>
</li>
<li>Spawning: creates a top-level task which ambiently runs a future to completion</li>
<li><p class="cn">Spawning: 创建一个顶级任务，该任务将积极地运行future直至完成</p>
</li>
<li><code>FuturesUnordered</code>: a group of futures which yields the result of each subfuture</li>
<li><p class="cn">`FuturesUnordered`: 返回每个子future结果的一组future</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="join"><a class="header" href="#join"><code>join!</code></a></h1>
<p>The <code>futures::join</code> macro makes it possible to wait for multiple different
futures to complete while executing them all concurrently.</p>
<p class="cn">
`futures::join`宏允许在同时执行多个不同的futures时等待它们完成。
</p>
<h1 id="join-1"><a class="header" href="#join-1"><code>join!</code></a></h1>
<p>When performing multiple asynchronous operations, it's tempting to simply
<code>.await</code> them in a series:</p>
<p class="cn">
当执行多个异步操作时，很简单容易地在一系列future中`.await`他们：
</p>
<pre><code class="language-rust edition2018 ignore">async fn get_book_and_music() -&gt; (Book, Music) {
    let book = get_book().await;
    let music = get_music().await;
    (book, music)
}
</code></pre>
<p>However, this will be slower than necessary, since it won't start trying to
<code>get_music</code> until after <code>get_book</code> has completed. In some other languages,
futures are ambiently run to completion, so two operations can be
run concurrently by first calling each <code>async fn</code> to start the futures, and
then awaiting them both:</p>
<p class="cn">
然而，这将比必要的速度慢，因为在`get_book`完成之前，它不会开始尝试`get_music`。
在其他一些语言中，futures会自动运行到完成，因此可以同时运行两个操作，首先调用每个`async fn`来启动futures，然后等待这两个操作：
</p>
<pre><code class="language-rust edition2018 ignore">// WRONG -- don't do this
async fn get_book_and_music() -&gt; (Book, Music) {
    let book_future = get_book();
    let music_future = get_music();
    (book_future.await, music_future.await)
}
</code></pre>
<p>However, Rust futures won't do any work until they're actively <code>.await</code>ed.
This means that the two code snippets above will both run
<code>book_future</code> and <code>music_future</code> in series rather than running them
concurrently. To correctly run the two futures concurrently, use
<code>futures::join!</code>:</p>
<p class="cn">
然而，Rust future不会起任何作用直到通过`.await`激活它。
这意味着上面的两段代码都将串联运行`book_future`和`music_future`，而不是同时运行它们。
要同时正确运行这两个未来，请使用`futures::join!`。
</p>
<pre><code class="language-rust edition2018 ignore">use futures::join;

async fn get_book_and_music() -&gt; (Book, Music) {
    let book_fut = get_book();
    let music_fut = get_music();
    join!(book_fut, music_fut)
}
</code></pre>
<p>The value returned by <code>join!</code> is a tuple containing the output of each
<code>Future</code> passed in.</p>
<p class="cn">
`join!`返回的值`是一个元组，包含传入的每个`Future`的输出。
</p>
<h2 id="try_join"><a class="header" href="#try_join"><code>try_join!</code></a></h2>
<p>For futures which return <code>Result</code>, consider using <code>try_join!</code> rather than
<code>join!</code>. Since <code>join!</code> only completes once all subfutures have completed,
it'll continue processing other futures even after one of its subfutures
has returned an <code>Err</code>.</p>
<p class="cn">
对于返回`Result`的future，请考虑使用`try_join!`而不是`join!`。
因为`join!`仅在所有子期future成后完成，它将继续处理其他future，即使其中一个子future返回“Err”。
</p>
<p>Unlike <code>join!</code>, <code>try_join!</code> will complete immediately if one of the subfutures
returns an error.</p>
<p class="cn">
不像`join!`, `try_join!`如果其中一个子未来返回错误，将立即完成。
</p>
<pre><code class="language-rust edition2018 ignore">use futures::try_join;

async fn get_book() -&gt; Result&lt;Book, String&gt; { /* ... */ Ok(Book) }
async fn get_music() -&gt; Result&lt;Music, String&gt; { /* ... */ Ok(Music) }

async fn get_book_and_music() -&gt; Result&lt;(Book, Music), String&gt; {
    let book_fut = get_book();
    let music_fut = get_music();
    try_join!(book_fut, music_fut)
}
</code></pre>
<p>Note that the futures passed to <code>try_join!</code> must all have the same error type.
Consider using the <code>.map_err(|e| ...)</code> and <code>.err_into()</code> functions from
<code>futures::future::TryFutureExt</code> to consolidate the error types:</p>
<p class="cn">
请注意，future传递给`try_join!`所有错误类型必须相同。
考虑使用来自`futures::future::TryFutureExt`的函数`.map_err(|e| ...)`和`.err_into()`以合并错误类型：
</p>
<pre><code class="language-rust edition2018 ignore">use futures::{
    future::TryFutureExt,
    try_join,
};

async fn get_book() -&gt; Result&lt;Book, ()&gt; { /* ... */ Ok(Book) }
async fn get_music() -&gt; Result&lt;Music, String&gt; { /* ... */ Ok(Music) }

async fn get_book_and_music() -&gt; Result&lt;(Book, Music), String&gt; {
    let book_fut = get_book().map_err(|()| &quot;Unable to get book&quot;.to_string());
    let music_fut = get_music();
    try_join!(book_fut, music_fut)
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="select"><a class="header" href="#select"><code>select!</code></a></h1>
<p>The <code>futures::select</code> macro runs multiple futures simultaneously, allowing
the user to respond as soon as any future completes.</p>
<p class="cn">
`futures::select`宏同时运行多个futures，允许用户在任何futures完成后立即响应。
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::{
    future::FutureExt, // for `.fuse()`
    pin_mut,
    select,
};

async fn task_one() { /* ... */ }
async fn task_two() { /* ... */ }

async fn race_tasks() {
    let t1 = task_one().fuse();
    let t2 = task_two().fuse();

    pin_mut!(t1, t2);

    select! {
        () = t1 =&gt; println!(&quot;task one completed first&quot;),
        () = t2 =&gt; println!(&quot;task two completed first&quot;),
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>The function above will run both <code>t1</code> and <code>t2</code> concurrently. When either
<code>t1</code> or <code>t2</code> finishes, the corresponding handler will call <code>println!</code>, and
the function will end without completing the remaining task.</p>
<p class="cn">
上述函数将同时运行't1'和't2'。当't1'或't2'完成时，相应的处理程序将调用`println!`，
该功能将在不完成剩余任务的情况下结束。
</p>
<p>The basic syntax for <code>select</code> is <code>&lt;pattern&gt; = &lt;expression&gt; =&gt; &lt;code&gt;,</code>,
repeated for as many futures as you would like to <code>select</code> over.</p>
<p class="cn">
`select`的基本语法是`<pattern> = <expression> => <code>`，重复你想要`select`的future。
</p>
<h2 id="default---and-complete--"><a class="header" href="#default---and-complete--"><code>default =&gt; ...</code> and <code>complete =&gt; ...</code></a></h2>
<p><code>select</code> also supports <code>default</code> and <code>complete</code> branches.</p>
<p class="cn">
`select`同时也支持`default`和`complete`分支
</p>
<p>A <code>default</code> branch will run if none of the futures being <code>select</code>ed
over are yet complete. A <code>select</code> with a <code>default</code> branch will
therefore always return immediately, since <code>default</code> will be run
if none of the other futures are ready.</p>
<p class="cn">
如果`select`的futures尚未完成，`default`分支将运行。
因此，带有`default`分支的 `select`总是会立即返回，因为如果没有其他future就绪，`default`将运行。
</p>
<p><code>complete</code> branches can be used to handle the case where all futures
being <code>select</code>ed over have completed and will no longer make progress.
This is often handy when looping over a <code>select!</code>.</p>
<p class="cn">
`complete`分支可用于处理所有正在`select`的future已完成且不再取得进展的情况。
当在`select!`上循环时，这通常很方便。
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::{future, select};

async fn count() {
    let mut a_fut = future::ready(4);
    let mut b_fut = future::ready(6);
    let mut total = 0;

    loop {
        select! {
            a = a_fut =&gt; total += a,
            b = b_fut =&gt; total += b,
            complete =&gt; break,
            default =&gt; unreachable!(), // never runs (futures are ready, then complete)
        };
    }
    assert_eq!(total, 10);
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="interaction-with-unpin-and-fusedfuture与unpin和fusedfuture的交互"><a class="header" href="#interaction-with-unpin-and-fusedfuture与unpin和fusedfuture的交互">Interaction with <code>Unpin</code> and <code>FusedFuture</code>(与<code>Unpin</code>和<code>FusedFuture</code>的交互`)</a></h2>
<p>One thing you may have noticed in the first example above is that we
had to call <code>.fuse()</code> on the futures returned by the two <code>async fn</code>s,
as well as pinning them with <code>pin_mut</code>. Both of these calls are necessary
because the futures used in <code>select</code> must implement both the <code>Unpin</code>
trait and the <code>FusedFuture</code> trait.</p>
<p class="cn">
在上面的第一个示例中，您可能已经注意到一件事，那就是我们必须在两个`async fn`返回的future上调用`.fuse()`，并用`pin_mut`固定它们。
这两个调用都是必要的，因为在`select`中使用的future必须实现`Unpin`特性和`FusedFuture`特性。
</p>
<p><code>Unpin</code> is necessary because the futures used by <code>select</code> are not
taken by value, but by mutable reference. By not taking ownership
of the future, uncompleted futures can be used again after the
call to <code>select</code>.</p>
<p class="cn">
`Unpin`是必需的，因为select使用的future不是按值，而是按可变引用。
通过不取得future的所有权，未完成的future可以在调用`select`后再次使用。
</p>
<p>Similarly, the <code>FusedFuture</code> trait is required because <code>select</code> must
not poll a future after it has completed. <code>FusedFuture</code> is implemented
by futures which track whether or not they have completed. This makes
it possible to use <code>select</code> in a loop, only polling the futures which
still have yet to complete. This can be seen in the example above,
where <code>a_fut</code> or <code>b_fut</code> will have completed the second time through
the loop. Because the future returned by <code>future::ready</code> implements
<code>FusedFuture</code>, it's able to tell <code>select</code> not to poll it again.</p>
<p class="cn">
同样，`FusedFuture`特性也是必需的，因为`select`必须在future完成后不轮询它.
future已实现`FusedFuture`，可以跟踪他们是否完成的。
这使得可以在循环中使用`select`，只轮询还没有完成的future。
这可以在上面的示例中看到，其中`a_fut`或`b_fut`将在第二次通过循环完成。
因为`future::ready`返回的future实现了`FusedFuture`，它可以告诉`select`不要再次轮询它。
</p>
<p>Note that streams have a corresponding <code>FusedStream</code> trait. Streams
which implement this trait or have been wrapped using <code>.fuse()</code>
will yield <code>FusedFuture</code> futures from their
<code>.next()</code> / <code>.try_next()</code> combinators.</p>
<p class="cn">
请注意，流具有相应的`FusedStream`特性。实现此特性或已使用`.fuse()`包装的流，
将从`.next()` / `.try_next()`组合符中产生实现了`FusedFuture`的future。
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::{
    stream::{Stream, StreamExt, FusedStream},
    select,
};

async fn add_two_streams(
    mut s1: impl Stream&lt;Item = u8&gt; + FusedStream + Unpin,
    mut s2: impl Stream&lt;Item = u8&gt; + FusedStream + Unpin,
) -&gt; u8 {
    let mut total = 0;

    loop {
        let item = select! {
            x = s1.next() =&gt; x,
            x = s2.next() =&gt; x,
            complete =&gt; break,
        };
        if let Some(next_num) = item {
            total += next_num;
        }
    }

    total
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="concurrent-tasks-in-a-select-loop-with-fuse-and-futuresunordered在select中使用fuse和futuresunordered的并行任务"><a class="header" href="#concurrent-tasks-in-a-select-loop-with-fuse-and-futuresunordered在select中使用fuse和futuresunordered的并行任务">Concurrent tasks in a <code>select</code> loop with <code>Fuse</code> and <code>FuturesUnordered</code>(在<code>select</code>中使用<code>Fuse</code>和<code>FuturesUnordered</code>的并行任务)</a></h2>
<p>One somewhat hard-to-discover but handy function is <code>Fuse::terminated()</code>,
which allows constructing an empty future which is already terminated,
and can later be filled in with a future that needs to be run.</p>
<p class="cn">
一个有点难以发现但很方便的函数是`Fuse::terminated()`，它允许构建一个已经终止的空future，以后可以填充需要运行的future。
</p>
<p>This can be handy when there's a task that needs to be run during a <code>select</code>
loop but which is created inside the <code>select</code> loop itself.</p>
<p class="cn">
当有一个任务需要在`select`循环中运行，但它是在`select`循环本身中创建的时，这会很方便。
</p>
<p>Note the use of the <code>.select_next_some()</code> function. This can be
used with <code>select</code> to only run the branch for <code>Some(_)</code> values
returned from the stream, ignoring <code>None</code>s.</p>
<p class="cn">
请注意`.select_next_some()`函数的用法。这可以与`select`一起使用，以便只对从流返回的`Some(_)`值运行分支，而忽略`None`。
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::{
    future::{Fuse, FusedFuture, FutureExt},
    stream::{FusedStream, Stream, StreamExt},
    pin_mut,
    select,
};

async fn get_new_num() -&gt; u8 { /* ... */ 5 }

async fn run_on_new_num(_: u8) { /* ... */ }

async fn run_loop(
    mut interval_timer: impl Stream&lt;Item = ()&gt; + FusedStream + Unpin,
    starting_num: u8,
) {
    let run_on_new_num_fut = run_on_new_num(starting_num).fuse();
    let get_new_num_fut = Fuse::terminated();
    pin_mut!(run_on_new_num_fut, get_new_num_fut);
    loop {
        select! {
            () = interval_timer.select_next_some() =&gt; {
                // The timer has elapsed. Start a new `get_new_num_fut`
                // if one was not already running.
                if get_new_num_fut.is_terminated() {
                    get_new_num_fut.set(get_new_num().fuse());
                }
            },
            new_num = get_new_num_fut =&gt; {
                // A new number has arrived -- start a new `run_on_new_num_fut`,
                // dropping the old one.
                run_on_new_num_fut.set(run_on_new_num(new_num).fuse());
            },
            // Run the `run_on_new_num_fut`
            () = run_on_new_num_fut =&gt; {},
            // panic if everything completed, since the `interval_timer` should
            // keep yielding values indefinitely.
            complete =&gt; panic!(&quot;`interval_timer` completed unexpectedly&quot;),
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>When many copies of the same future need to be run simultaneously,
use the <code>FuturesUnordered</code> type. The following example is similar
to the one above, but will run each copy of <code>run_on_new_num_fut</code>
to completion, rather than aborting them when a new one is created.
It will also print out a value returned by <code>run_on_new_num_fut</code>.</p>
<p class="cn">
当需要同时运行同一future的多个副本时，请使用`FuturesUnordered`类型。
以下示例与上面的示例类似，但将运行`run_on_new_num_fut`的每个副本直到完成，而不是在创建新副本时中止它们。
它还将打印`run_on_new_num_fut`返回的值。
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::{
    future::{Fuse, FusedFuture, FutureExt},
    stream::{FusedStream, FuturesUnordered, Stream, StreamExt},
    pin_mut,
    select,
};

async fn get_new_num() -&gt; u8 { /* ... */ 5 }

async fn run_on_new_num(_: u8) -&gt; u8 { /* ... */ 5 }

// Runs `run_on_new_num` with the latest number
// retrieved from `get_new_num`.
//
// `get_new_num` is re-run every time a timer elapses,
// immediately cancelling the currently running
// `run_on_new_num` and replacing it with the newly
// returned value.
async fn run_loop(
    mut interval_timer: impl Stream&lt;Item = ()&gt; + FusedStream + Unpin,
    starting_num: u8,
) {
    let mut run_on_new_num_futs = FuturesUnordered::new();
    run_on_new_num_futs.push(run_on_new_num(starting_num));
    let get_new_num_fut = Fuse::terminated();
    pin_mut!(get_new_num_fut);
    loop {
        select! {
            () = interval_timer.select_next_some() =&gt; {
                // The timer has elapsed. Start a new `get_new_num_fut`
                // if one was not already running.
                if get_new_num_fut.is_terminated() {
                    get_new_num_fut.set(get_new_num().fuse());
                }
            },
            new_num = get_new_num_fut =&gt; {
                // A new number has arrived -- start a new `run_on_new_num_fut`.
                run_on_new_num_futs.push(run_on_new_num(new_num));
            },
            // Run the `run_on_new_num_futs` and check if any have completed
            res = run_on_new_num_futs.select_next_some() =&gt; {
                println!(&quot;run_on_new_num_fut returned {:?}&quot;, res);
            },
            // panic if everything completed, since the `interval_timer` should
            // keep yielding values indefinitely.
            complete =&gt; panic!(&quot;`interval_timer` completed unexpectedly&quot;),
        }
    }
}

<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="workarounds-to-know-and-love需要了解和热爱的变通方法"><a class="header" href="#workarounds-to-know-and-love需要了解和热爱的变通方法">Workarounds to Know and Love(需要了解和热爱的变通方法)</a></h1>
<p>Rust's <code>async</code> support is still fairly new, and there are a handful of
highly-requested features still under active development, as well
as some subpar diagnostics. This chapter will discuss some common pain
points and explain how to work around them.</p>
<p class="cn">
Rust的`async`支持仍然相当新，还有一些高要求的功能仍在积极开发中，以及一些次级诊断。
本章将讨论一些常见的痛点，并解释如何解决这些痛点。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-in-async-blocksasync块中的"><a class="header" href="#-in-async-blocksasync块中的"><code>?</code> in <code>async</code> Blocks(<code>async</code>块中的<code>?</code>)</a></h1>
<p>Just as in <code>async fn</code>, it's common to use <code>?</code> inside <code>async</code> blocks.
However, the return type of <code>async</code> blocks isn't explicitly stated.
This can cause the compiler to fail to infer the error type of the
<code>async</code> block.</p>
<p class="cn">
就像在`async fn`中一样，经常在`async`块内使用`?`。
但是，`async`块的返回类型没有明确说明。
这可能会导致编译器无法推断`async`块的错误类型。
</p>
<p>For example, this code:</p>
<p class="cn">
例如下面的代码：
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">struct MyError;
</span><span class="boring">async fn foo() -&gt; Result&lt;(), MyError&gt; { Ok(()) }
</span><span class="boring">async fn bar() -&gt; Result&lt;(), MyError&gt; { Ok(()) }
</span>let fut = async {
    foo().await?;
    bar().await?;
    Ok(())
};
<span class="boring">}
</span></code></pre></pre>
<p>will trigger this error:</p>
<p class="cn">
将会触发这个错误：
</p>
<pre><code>error[E0282]: type annotations needed
 --&gt; src/main.rs:5:9
  |
4 |     let fut = async {
  |         --- consider giving `fut` a type
5 |         foo().await?;
  |         ^^^^^^^^^^^^ cannot infer type
</code></pre>
<p>Unfortunately, there's currently no way to &quot;give <code>fut</code> a type&quot;, nor a way
to explicitly specify the return type of an <code>async</code> block.
To work around this, use the &quot;turbofish&quot; operator to supply the success and
error types for the <code>async</code> block:</p>
<p class="cn">
不幸的是，目前没有办法"给`fut`一个类型"，也没有办法显式指定`async`块的返回类型。
要解决此问题，请使用`turbofish`操作符为`async`块提供成功和错误类型：
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">struct MyError;
</span><span class="boring">async fn foo() -&gt; Result&lt;(), MyError&gt; { Ok(()) }
</span><span class="boring">async fn bar() -&gt; Result&lt;(), MyError&gt; { Ok(()) }
</span>let fut = async {
    foo().await?;
    bar().await?;
    Ok::&lt;(), MyError&gt;(()) // &lt;- note the explicit type annotation here
};
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="send-approximationsend的相似问题"><a class="header" href="#send-approximationsend的相似问题"><code>Send</code> Approximation(<code>Send</code>的相似问题)</a></h1>
<p>Some <code>async fn</code> state machines are safe to be sent across threads, while
others are not. Whether or not an <code>async fn</code> <code>Future</code> is <code>Send</code> is determined
by whether a non-<code>Send</code> type is held across an <code>.await</code> point. The compiler
does its best to approximate when values may be held across an <code>.await</code>
point, but this analysis is too conservative in a number of places today.</p>
<p class="cn">
一些`async fn`状态机可以安全地跨线程发送，而其他状态机则不安全。
`async fn` `Future`是否可`Send`取决于在跨越一个`.await`点，是否持有非`Send`类型。
编译器尽最大努力来估计在跨越一个`.await`点的值的保留时间，但这种分析在今天的一些地方过于保守。
</p>
<p>For example, consider a simple non-<code>Send</code> type, perhaps a type
which contains an <code>Rc</code>:</p>
<p class="cn">
例如，考虑一个简单的非`Send`类型，可能是一个包含`Rc`的类型：
</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::rc::Rc;

#[derive(Default)]
struct NotSend(Rc&lt;()&gt;);
<span class="boring">}
</span></code></pre></pre>
<p>Variables of type <code>NotSend</code> can briefly appear as temporaries in <code>async fn</code>s
even when the resulting <code>Future</code> type returned by the <code>async fn</code> must be <code>Send</code>:</p>
<p class="cn">
即使`async fn`返回的结果`Future`类型必须为`Send`，类型为`NotSend`的变量也可以在`async fn`中短暂显示为临时变量：
</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Default)]
</span><span class="boring">struct NotSend(Rc&lt;()&gt;);
</span>async fn bar() {}
async fn foo() {
    NotSend::default();
    bar().await;
}

fn require_send(_: impl Send) {}

fn main() {
    require_send(foo());
}
</code></pre></pre>
<p>However, if we change <code>foo</code> to store <code>NotSend</code> in a variable, this example no
longer compiles:</p>
<p class="cn">
但是，如果将`foo`更改为在变量中存储`NotSend`，则此示例将不再可编译：
</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Default)]
</span><span class="boring">struct NotSend(Rc&lt;()&gt;);
</span><span class="boring">async fn bar() {}
</span>async fn foo() {
    let x = NotSend::default();
    bar().await;
}
<span class="boring">fn require_send(_: impl Send) {}
</span><span class="boring">fn main() {
</span><span class="boring">   require_send(foo());
</span><span class="boring">}
</span></code></pre></pre>
<pre><code>error[E0277]: `std::rc::Rc&lt;()&gt;` cannot be sent between threads safely
  --&gt; src/main.rs:15:5
   |
15 |     require_send(foo());
   |     ^^^^^^^^^^^^ `std::rc::Rc&lt;()&gt;` cannot be sent between threads safely
   |
   = help: within `impl std::future::Future`, the trait `std::marker::Send` is not implemented for `std::rc::Rc&lt;()&gt;`
   = note: required because it appears within the type `NotSend`
   = note: required because it appears within the type `{NotSend, impl std::future::Future, ()}`
   = note: required because it appears within the type `[static generator@src/main.rs:7:16: 10:2 {NotSend, impl std::future::Future, ()}]`
   = note: required because it appears within the type `std::future::GenFuture&lt;[static generator@src/main.rs:7:16: 10:2 {NotSend, impl std::future::Future, ()}]&gt;`
   = note: required because it appears within the type `impl std::future::Future`
   = note: required because it appears within the type `impl std::future::Future`
note: required by `require_send`
  --&gt; src/main.rs:12:1
   |
12 | fn require_send(_: impl Send) {}
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error: aborting due to previous error

For more information about this error, try `rustc --explain E0277`.
</code></pre>
<p>This error is correct. If we store <code>x</code> into a variable, it won't be dropped
until after the <code>.await</code>, at which point the <code>async fn</code> may be running on
a different thread. Since <code>Rc</code> is not <code>Send</code>, allowing it to travel across
threads would be unsound. One simple solution to this would be to <code>drop</code>
the <code>Rc</code> before the <code>.await</code>, but unfortunately that does not work today.</p>
<p class="cn">
此错误是正确的。如果我们将'x'存储到变量中，则直到`.await`之后才会删除它，此时'async fn'可能正在另一个线程上运行。
由于'Rc'不是'Send'，允许它在线程之间移动是不合理的。
解决这个问题的一个简单方法是在`.await`之前丢弃掉`Rc`，但不幸的是，这在今天不起作用。
</p>
<p>In order to successfully work around this issue, you may have to introduce
a block scope encapsulating any non-<code>Send</code> variables. This makes it easier
for the compiler to tell that these variables do not live across an
<code>.await</code> point.</p>
<p class="cn">
为了成功解决这个问题，您可能需要引入一个块范围来封装任何非`Send`变量。
这使得编译器更容易判断这些变量不跨`.await`点。
</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Default)]
</span><span class="boring">struct NotSend(Rc&lt;()&gt;);
</span><span class="boring">async fn bar() {}
</span>async fn foo() {
    {
        let x = NotSend::default();
    }
    bar().await;
}
<span class="boring">fn require_send(_: impl Send) {}
</span><span class="boring">fn main() {
</span><span class="boring">   require_send(foo());
</span><span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recursion递归"><a class="header" href="#recursion递归">Recursion(递归)</a></h1>
<p>Internally, <code>async fn</code> creates a state machine type containing each
sub-<code>Future</code> being <code>.await</code>ed. This makes recursive <code>async fn</code>s a little
tricky, since the resulting state machine type has to contain itself:</p>
<p class="cn">
在内部，`async fn`创建一个状态机类型，其中包含每个正在`.await`的子`Future`。
这使得递归`async fn`有点棘手，因为生成的状态机类型必须包含自己：
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">async fn step_one() { /* ... */ }
</span><span class="boring">async fn step_two() { /* ... */ }
</span><span class="boring">struct StepOne;
</span><span class="boring">struct StepTwo;
</span>// This function:
async fn foo() {
    step_one().await;
    step_two().await;
}
// generates a type like this:
enum Foo {
    First(StepOne),
    Second(StepTwo),
}

// So this function:
async fn recursive() {
    recursive().await;
    recursive().await;
}

// generates a type like this:
enum Recursive {
    First(Recursive),
    Second(Recursive),
}
<span class="boring">}
</span></code></pre></pre>
<p>This won't work—we've created an infinitely-sized type!
The compiler will complain:</p>
<p class="cn">
这行不通，我们已经创建了一个无限大小的类型！
编译器将抱怨：
</p>
<pre><code>error[E0733]: recursion in an `async fn` requires boxing
 --&gt; src/lib.rs:1:22
  |
1 | async fn recursive() {
  |                      ^ an `async fn` cannot invoke itself directly
  |
  = note: a recursive `async fn` must be rewritten to return a boxed future.
</code></pre>
<p>In order to allow this, we have to introduce an indirection using <code>Box</code>.
Unfortunately, compiler limitations mean that just wrapping the calls to
<code>recursive()</code> in <code>Box::pin</code> isn't enough. To make this work, we have
to make <code>recursive</code> into a non-<code>async</code> function which returns a <code>.boxed()</code>
<code>async</code> block:</p>
<p class="cn">
为了实现这一点，我们必须引入一个使用`Box`的间接寻址。
不幸的是，编译器的限制意味着仅仅将对`recursive()`的调用包装在`Box::pin`中是不够的。
为了实现这一点，我们必须将`recursive`转换为一个非`async`函数，该函数返回一个`.boxed()` `async`块：
</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::future::{BoxFuture, FutureExt};

fn recursive() -&gt; BoxFuture&lt;'static, ()&gt; {
    async move {
        recursive().await;
        recursive().await;
    }.boxed()
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="async-in-traitsasync特征化"><a class="header" href="#async-in-traitsasync特征化"><code>async</code> in Traits(<code>async</code>特征化)</a></h1>
<p>Currently, <code>async fn</code> cannot be used in traits. The reasons for this are
somewhat complex, but there are plans to remove this restriction in the
future.</p>
<p class="cn">
目前，`async fn`不能用于traits。原因有点复杂，但将来有计划取消这一限制。
</p>
<p>In the meantime, however, this can be worked around using the
<a href="https://github.com/dtolnay/async-trait">async-trait crate from crates.io</a>.</p>
<p class="cn">
然而，在此期间，可以使用<a href="https://github.com/dtolnay/async-trait">async-trait crate from crates.io</a>
</p>
<p>Note that using these trait methods will result in a heap allocation
per-function-call. This is not a significant cost for the vast majority
of applications, but should be considered when deciding whether to use
this functionality in the public API of a low-level function that is expected
to be called millions of times a second.</p>
<p class="cn">
请注意，使用这些trait方法将导致每个函数调用的堆分配。对于绝大多数应用程序来说，这并不是一个很大的成本，
但在决定是否在预计每秒会被调用数百万次低级别函数的公共API中使用此功能时，应该考虑到这一点。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-async-ecosystem异步生态"><a class="header" href="#the-async-ecosystem异步生态">The Async Ecosystem(异步生态)</a></h1>
<p>Rust currently provides only the bare essentials for writing async code.
Importantly, executors, tasks, reactors, combinators, and low-level I/O futures and traits
are not yet provided in the standard library. In the meantime,
community-provided async ecosystems fill in these gaps.</p>
<p class="cn">
Rust目前只提供编写异步代码的基本要素。
重要的是，标准库中尚未提供执行器、任务、反应器、组合器和低级I/O future和traits。
与此同时，社区提供的异步生态系统填补了这些空白。
</p>
<p>The Async Foundations Team is interested in extending examples in the Async Book to cover multiple runtimes.
If you're interested in contributing to this project, please reach out to us on
<a href="https://rust-lang.zulipchat.com/#narrow/stream/201246-wg-async-foundations.2Fbook">Zulip</a>.</p>
<p class="cn">
Async Foundation团队对扩展Async书籍中的示例以涵盖多个运行时很感兴趣。
如果您有兴趣为这个项目做出贡献，请联系我们
<a href="https://rust-lang.zulipchat.com/#narrow/stream/201246-wg-async-foundations.2Fbook">Zulip</a>
</p>
<h2 id="async-runtimes异步运行时"><a class="header" href="#async-runtimes异步运行时">Async Runtimes(异步运行时)</a></h2>
<p>Async runtimes are libraries used for executing async applications.
Runtimes usually bundle together a <em>reactor</em> with one or more <em>executors</em>.
Reactors provide subscription mechanisms for external events, like async I/O, interprocess communication, and timers.
In an async runtime, subscribers are typically futures representing low-level I/O operations.
Executors handle the scheduling and execution of tasks.
They keep track of running and suspended tasks, poll futures to completion, and wake tasks when they can make progress.
The word &quot;executor&quot; is frequently used interchangeably with &quot;runtime&quot;.
Here, we use the word &quot;ecosystem&quot; to describe a runtime bundled with compatible traits and features.</p>
<p class="cn">
异步运行时是用于执行异步应用程序的库。
运行时通常将一个*反应器*与一个或多个*执行器*捆绑在一起。
反应器为外部事件提供订阅机制，如异步I/O、进程间通信和计时器。
在异步运行时中，订阅服务器通常是表示低级I/O操作的future。
执行器处理任务的调度和执行。
它们跟踪正在运行和暂停的任务，轮询future以完成任务，并在任务能够取得进展时唤醒任务。
“executor”一词经常与“runtime”互换使用。
这里，我们使用“生态系统”一词来描述与兼容traits和特性捆绑在一起的运行时。
</p>
<h2 id="community-provided-async-crates社区提供的异步crates"><a class="header" href="#community-provided-async-crates社区提供的异步crates">Community-Provided Async Crates(社区提供的异步Crates)</a></h2>
<h3 id="the-futures-cratefutures-crate"><a class="header" href="#the-futures-cratefutures-crate">The Futures Crate(Futures Crate)</a></h3>
<p>The <a href="https://docs.rs/futures/"><code>futures</code> crate</a> contains traits and functions useful for writing async code.
This includes the <code>Stream</code>, <code>Sink</code>, <code>AsyncRead</code>, and <code>AsyncWrite</code> traits, and utilities such as combinators.
These utilities and traits may eventually become part of the standard library.</p>
<p class="cn">
<a href="https://docs.rs/futures/">`futures` crate</a>包含对编写异步代码有用的特征和函数。
这包括`Stream`, `Sink`, `AsyncRead`和`AsyncWrite`特征，以及诸如组合器之类的实用程序。
这些实用程序和特征最终可能成为标准库的一部分。
</p>
<p><code>futures</code> has its own executor, but not its own reactor, so it does not support execution of async I/O or timer futures.
For this reason, it's not considered a full runtime.
A common choice is to use utilities from <code>futures</code> with an executor from another crate.</p>
<p class="cn">
`futures`有自己的执行器，但没有自己的反应器，因此它不支持异步I/O或计时器future的执行。
因此，它不被视为完整的运行时。
一种常见的选择是与另一个板条箱的执行器一起使用`futures`中的实用程序。
</p>
<h3 id="popular-async-runtimes流行的运行时"><a class="header" href="#popular-async-runtimes流行的运行时">Popular Async Runtimes(流行的运行时)</a></h3>
<p>There is no asynchronous runtime in the standard library, and none are officially recommended.
The following crates provide popular runtimes.</p>
<p class="cn">
标准库中没有异步运行时，官方也不推荐使用。
以下板条箱提供了流行的运行时。
</p>
<ul>
<li><a href="https://docs.rs/tokio/">Tokio</a>: A popular async ecosystem with HTTP, gRPC, and tracing frameworks.</li>
<li><p class="cn"><a href="https://docs.rs/tokio/">Tokio</a>: 一个流行的异步生态，包括HTTP, gRPC和调用追踪框架</p>
</li>
<li><a href="https://docs.rs/async-std/">async-std</a>: A crate that provides asynchronous counterparts to standard library components.</li>
<li><p class="cn"><a href="https://docs.rs/async-std/">async-std</a>: 为标准库组件提供异步副本的板条箱</p>
</li>
<li><a href="https://docs.rs/smol/">smol</a>: A small, simplified async runtime.
Provides the <code>Async</code> trait that can be used to wrap structs like <code>UnixStream</code> or <code>TcpListener</code>.</li>
<li><p class="cn"><a href="https://docs.rs/smol/">smol</a>: 一个小而简单的异步运行时。提供了`Async`特征可以用来包装`UnixStream`或者`TcpListener`等结构</p>
</li>
<li><a href="https://www.baidu.com/">fuchsia-async</a>:
An executor for use in the Fuchsia OS.</li>
<li><p class="cn"><a href="https://www.baidu.com/">fuchsia-async</a>: 一个在Fuchsia OS中使用的执行器</p>
</li>
</ul>
<h2 id="determining-ecosystem-compatibility确定生态系统兼容性"><a class="header" href="#determining-ecosystem-compatibility确定生态系统兼容性">Determining Ecosystem Compatibility(确定生态系统兼容性)</a></h2>
<p>Not all async applications, frameworks, and libraries are compatible with each other, or with every OS or platform.
Most async code can be used with any ecosystem, but some frameworks and libraries require the use of a specific ecosystem.
Ecosystem constraints are not always documented, but there are several rules of thumb to determine
whether a library, trait, or function depends on a specific ecosystem.</p>
<p class="cn">
并非所有异步应用程序、框架和库都彼此兼容，或者与每个操作系统或平台兼容。
大多数异步代码可以用于任何生态系统，但一些框架和库需要使用特定的生态系统。
生态系统限制并不总是有文档记录的，但有几个经验法则可以确定库、特征或功能是否依赖于特定的生态系统。
</p>
<p>Any async code that interacts with async I/O, timers, interprocess communication, or tasks
generally depends on a specific async executor or reactor.
All other async code, such as async expressions, combinators, synchronization types, and streams
are usually ecosystem independent, provided that any nested futures are also ecosystem independent.
Before beginning a project, it's recommended to research relevant async frameworks and libraries to ensure
compatibility with your chosen runtime and with each other.</p>
<p class="cn">
与异步I/O、计时器、进程间通信或任务交互的任何异步代码通常取决于特定的异步执行器或反应器。
所有其他异步代码（如异步表达式、组合符、同步类型和流）通常与生态系统无关，前提是任何嵌套的future也与生态系统无关。
在开始一个项目之前，建议研究相关的异步框架和库，以确保与您选择的运行时以及彼此之间的兼容性。
</p>
<p>Notably, <code>Tokio</code> uses the <code>mio</code> reactor and defines its own versions of async I/O traits,
including <code>AsyncRead</code> and <code>AsyncWrite</code>.
On its own, it's not compatible with <code>async-std</code> and <code>smol</code>,
which rely on the <a href="https://docs.rs/async-executor"><code>async-executor</code> crate</a>, and the <code>AsyncRead</code> and <code>AsyncWrite</code>
traits defined in <code>futures</code>.</p>
<p class="cn">
值得注意的是，`Tokio`使用了`mio`反应器，并定义了自己的异步I/O特性版本，包括`AsyncRead`和`AsyncWrite`。
就其本身而言，它与依赖于<a href="https://docs.rs/async-executor">`async-executor` crate</a>，
并且`AsyncRead`和`AsyncWrite`来自于`futures`的`async-std`和`smol`不兼容
</p>
<p>Conflicting runtime requirements can sometimes be resolved by compatibility layers
that allow you to call code written for one runtime within another.
For example, the <a href="https://docs.rs/async_compat"><code>async_compat</code> crate</a> provides a compatibility layer between
<code>Tokio</code> and other runtimes.</p>
<p class="cn">
有时，冲突的运行时需求可以通过兼容层来解决，兼容层允许您在另一个运行时中调用为一个运行时编写的代码。
例如，<a href="https://docs.rs/async_compat">`async_compat` crate</a>提供了在`Tokio`和其他运行时直接的兼容层
</p>
<p>Libraries exposing async APIs should not depend on a specific executor or reactor,
unless they need to spawn tasks or define their own async I/O or timer futures.
Ideally, only binaries should be responsible for scheduling and running tasks.</p>
<p class="cn">
公开异步API的库不应依赖于特定的执行器或反应器，
除非他们需要生成任务或定义自己的异步I/O或计时器未来。
理想情况下，应该只有二进制文件负责调度和运行任务。
</p>
<h2 id="single-threaded-vs-multi-threaded-executors单线程对比多线程执行器"><a class="header" href="#single-threaded-vs-multi-threaded-executors单线程对比多线程执行器">Single Threaded vs Multi-Threaded Executors(单线程对比多线程执行器)</a></h2>
<p>Async executors can be single-threaded or multi-threaded.
For example, the <code>async-executor</code> crate has both a single-threaded <code>LocalExecutor</code> and a multi-threaded <code>Executor</code>.</p>
<p class="cn">
异步执行器可以是单线程或多线程的。
例如，`async executor`板条箱既有一个单线程的`LocalExecutor`，也有一个多线程的`executor`。
</p>
<p>A multi-threaded executor makes progress on several tasks simultaneously.
It can speed up the execution greatly for workloads with many tasks,
but synchronizing data between tasks is usually more expensive.
It is recommended to measure performance for your application
when you are choosing between a single- and a multi-threaded runtime.</p>
<p class="cn">
多线程执行器同时在多个任务上取得进展。
对于有许多任务的工作负载，它可以大大加快执行速度，但在任务之间同步数据通常成本更高。
在单线程和多线程运行时之间进行选择时，建议测量应用程序的性能。
</p>
<p>Tasks can either be run on the thread that created them or on a separate thread.
Async runtimes often provide functionality for spawning tasks onto separate threads.
Even if tasks are executed on separate threads, they should still be non-blocking.
In order to schedule tasks on a multi-threaded executor, they must also be <code>Send</code>.
Some runtimes provide functions for spawning non-<code>Send</code> tasks,
which ensures every task is executed on the thread that spawned it.
They may also provide functions for spawning blocking tasks onto dedicated threads,
which is useful for running blocking synchronous code from other libraries.</p>
<p class="cn">
任务可以在创建它们的线程上运行，也可以在单独的线程上运行。
异步运行时通常提供将任务派生到单独线程的功能。
即使任务在单独的线程上执行，它们也应该是非阻塞的。
为了在多线程执行器上调度任务，它们还必须是可“Send”的。
一些运行时提供了派生非“Send”任务的函数，确保每个任务都在派生它的线程上执行。
它们还可以提供将阻塞任务派生到专用线程的函数，这对于从其他库运行阻塞同步代码很有用。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="final-project-building-a-concurrent-web-server-with-async-rust最终项目使用rust异步编程构建一个并发web服务器"><a class="header" href="#final-project-building-a-concurrent-web-server-with-async-rust最终项目使用rust异步编程构建一个并发web服务器">Final Project: Building a Concurrent Web Server with Async Rust(最终项目：使用Rust异步编程构建一个并发web服务器)</a></h1>
<p>In this chapter, we'll use asynchronous Rust to modify the Rust book's 
<a href="https://doc.rust-lang.org/book/ch20-01-single-threaded.html">single-threaded web server</a> 
to serve requests concurrently.</p>
<p class="cn">
在本章中，我们将使用异步Rust来修改Rust手册的
<a href="https://doc.rust-lang.org/book/ch20-01-single-threaded.html">单线程web server</a>来支持并发的响应请求。
</p>
<h2 id="recap回顾"><a class="header" href="#recap回顾">Recap(回顾)</a></h2>
<p>Here's what the code looked like at the end of the lesson.</p>
<p class="cn">
那门课程的代码大概是如下
</p>
<p><code>src/main.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust">use std::fs;
use std::io::prelude::*;
use std::net::TcpListener;
use std::net::TcpStream;

fn main() {
    // Listen for incoming TCP connections on localhost port 7878
    let listener = TcpListener::bind(&quot;127.0.0.1:7878&quot;).unwrap();

    // Block forever, handling each request that arrives at this IP address
    for stream in listener.incoming() {
        let stream = stream.unwrap();

        handle_connection(stream);
    }
}

fn handle_connection(mut stream: TcpStream) {
    // Read the first 1024 bytes of data from the stream
    let mut buffer = [0; 1024];
    stream.read(&amp;mut buffer).unwrap();

    let get = b&quot;GET / HTTP/1.1\r\n&quot;;

    // Respond with greetings or a 404,
    // depending on the data in the request
    let (status_line, filename) = if buffer.starts_with(get) {
        (&quot;HTTP/1.1 200 OK\r\n\r\n&quot;, &quot;hello.html&quot;)
    } else {
        (&quot;HTTP/1.1 404 NOT FOUND\r\n\r\n&quot;, &quot;404.html&quot;)
    };
    let contents = fs::read_to_string(filename).unwrap();

    // Write response back to the stream,
    // and flush the stream to ensure the response is sent back to the client
    let response = format!(&quot;{status_line}{contents}&quot;);
    stream.write_all(response.as_bytes()).unwrap();
    stream.flush().unwrap();
}
</code></pre></pre>
<p><code>hello.html</code>:</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;utf-8&quot;&gt;
    &lt;title&gt;Hello!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello!&lt;/h1&gt;
    &lt;p&gt;Hi from Rust&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><code>404.html</code>:</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;utf-8&quot;&gt;
    &lt;title&gt;Hello!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Oops!&lt;/h1&gt;
    &lt;p&gt;Sorry, I don't know what you're asking for.&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>If you run the server with <code>cargo run</code> and visit <code>127.0.0.1:7878</code> in your browser,
you'll be greeted with a friendly message from Ferris!</p>
<p class="cn">
如果你使用`cargo run`命令运行，并在浏览器访问`127.0.0.1:7878`，
你将会得到一句友好的欢迎语！
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-asynchronous-code运行异步代码"><a class="header" href="#running-asynchronous-code运行异步代码">Running Asynchronous Code(运行异步代码)</a></h1>
<p>An HTTP server should be able to serve multiple clients concurrently;
that is, it should not wait for previous requests to complete before handling the current request.
The book
<a href="https://doc.rust-lang.org/book/ch20-02-multithreaded.html#turning-our-single-threaded-server-into-a-multithreaded-server">solves this problem</a>
by creating a thread pool where each connection is handled on its own thread.
Here, instead of improving throughput by adding threads, we'll achieve the same effect using asynchronous code.</p>
<p class="cn">
HTTP服务器应该能够同时为多个客户端提供服务；
也就是说，它不应该在处理当前请求之前等待以前的请求完成。
这本书<a href="https://doc.rust-lang.org/book/ch20-02-multithreaded.html#turning-our-single-threaded-server-into-a-multithreaded-server">solves this problem</a>通过创建线程池让每一个请求都在他们自己的线程中处理。
在这里，我们将使用异步代码来实现相同的效果，而不是通过添加线程来提高吞吐量。
</p>
<p>Let's modify <code>handle_connection</code> to return a future by declaring it an <code>async fn</code>:</p>
<p class="cn">
让我们修改`handle_connection`，通过将其声明为`async fn`来返回future：
</p>
<pre><code class="language-rust ignore">async fn handle_connection(mut stream: TcpStream) {
    //&lt;-- snip --&gt;
}
</code></pre>
<p>Adding <code>async</code> to the function declaration changes its return type
from the unit type <code>()</code> to a type that implements <code>Future&lt;Output=()&gt;</code>.</p>
<p class="cn">
将`async`添加到函数声明中会将其返回类型从单元类型`()`更改为实现`Future<Output=()>`的类型。
</p>
<p>If we try to compile this, the compiler warns us that it will not work:</p>
<p class="cn">
如果我们试图编译它，编译器会警告我们它将无法工作：
</p>
<pre><code class="language-console">$ cargo check
    Checking async-rust v0.1.0 (file:///projects/async-rust)
warning: unused implementer of `std::future::Future` that must be used
  --&gt; src/main.rs:12:9
   |
12 |         handle_connection(stream);
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = note: `#[warn(unused_must_use)]` on by default
   = note: futures do nothing unless you `.await` or poll them
</code></pre>
<p>Because we haven't <code>await</code>ed or <code>poll</code>ed the result of <code>handle_connection</code>,
it'll never run. If you run the server and visit <code>127.0.0.1:7878</code> in a browser,
you'll see that the connection is refused; our server is not handling requests.</p>
<p class="cn">
因为我们没有`await`或`poll` `handle_connection`的结果，所以它永远不会运行。
如果运行服务器并在浏览器中访问“127.0.0.1:7878”，
您将看到连接被拒绝；我们的服务器没有处理请求。
</p>
<p>We can't <code>await</code> or <code>poll</code> futures within synchronous code by itself.
We'll need an asynchronous runtime to handle scheduling and running futures to completion.
Please consult the <a href="09_example/../08_ecosystem/00_chapter.html">section on choosing a runtime</a>
for more information on asynchronous runtimes, executors, and reactors.
Any of the runtimes listed will work for this project, but for these examples,
we've chosen to use the <code>async-std</code> crate.</p>
<p class="cn">
我们不能单独在同步代码中“等待”或“轮询”未来。
我们需要一个异步运行时来处理调度和运行期货直到完成。
请参考<a href="09_example/../08_ecosystem/00_chapter.html">section on choosing a runtime</a>
获取更多关于异步运行时，执行器和反应器的信息。
列出的任何运行时都适用于此项目，但对于这里的示例，我们选择使用`async std`板条箱。
</p>
<h2 id="adding-an-async-runtime添加一个异步运行时"><a class="header" href="#adding-an-async-runtime添加一个异步运行时">Adding an Async Runtime(添加一个异步运行时)</a></h2>
<p>The following example will demonstrate refactoring synchronous code to use an async runtime; here, <code>async-std</code>.
The <code>#[async_std::main]</code> attribute from <code>async-std</code> allows us to write an asynchronous main function.
To use it, enable the <code>attributes</code> feature of <code>async-std</code> in <code>Cargo.toml</code>:</p>
<p class="cn">
以下示例将演示如何重构同步代码以使用异步运行时；此处为`async-std`。
`async-std`中的`#[async_std::main]`属性允许我们编写异步main函数。
要使用它，请在`Cargo.toml`中启用`async-std`的`attributes`特性:
</p>
<pre><code class="language-toml">[dependencies.async-std]
version = &quot;1.6&quot;
features = [&quot;attributes&quot;]
</code></pre>
<p>As a first step, we'll switch to an asynchronous main function,
and <code>await</code> the future returned by the async version of <code>handle_connection</code>.
Then, we'll test how the server responds.
Here's what that would look like:</p>
<p class="cn">
作为第一步，我们将切换到异步主函数，
和`await`由`handle_connection`的异步版本返回的future。
然后，我们将测试服务器如何响应。
下面是修改后代码：
</p>
<pre><pre class="playground"><code class="language-rust">#[async_std::main]
async fn main() {
    let listener = TcpListener::bind(&quot;127.0.0.1:7878&quot;).unwrap();
    for stream in listener.incoming() {
        let stream = stream.unwrap();
        // Warning: This is not concurrent!
        handle_connection(stream).await;
    }
}
</code></pre></pre>
<p>Now, let's test to see if our server can handle connections concurrently.
Simply making <code>handle_connection</code> asynchronous doesn't mean that the server
can handle multiple connections at the same time, and we'll soon see why.</p>
<p class="cn">
现在，让我们测试一下服务器是否可以并发处理连接。
简单地将`handle_connection`设置为异步并不意味着服务器可以同时处理多个连接，我们很快就会知道原因。
</p>
<p>To illustrate this, let's simulate a slow request.
When a client makes a request to <code>127.0.0.1:7878/sleep</code>,
our server will sleep for 5 seconds:</p>
<p class="cn">
为了说明这一点，让我们模拟一个缓慢的请求。当客户端请求 `127.0.0.1:7878/sleep`时，我们的服务器将睡眠5秒钟：
</p>
<pre><code class="language-rust ignore">use async_std::task;

async fn handle_connection(mut stream: TcpStream) {
    let mut buffer = [0; 1024];
    stream.read(&amp;mut buffer).unwrap();

    let get = b&quot;GET / HTTP/1.1\r\n&quot;;
    let sleep = b&quot;GET /sleep HTTP/1.1\r\n&quot;;

    let (status_line, filename) = if buffer.starts_with(get) {
        (&quot;HTTP/1.1 200 OK\r\n\r\n&quot;, &quot;hello.html&quot;)
    } else if buffer.starts_with(sleep) {
        task::sleep(Duration::from_secs(5)).await;
        (&quot;HTTP/1.1 200 OK\r\n\r\n&quot;, &quot;hello.html&quot;)
    } else {
        (&quot;HTTP/1.1 404 NOT FOUND\r\n\r\n&quot;, &quot;404.html&quot;)
    };
    let contents = fs::read_to_string(filename).unwrap();

    let response = format!(&quot;{status_line}{contents}&quot;);
    stream.write(response.as_bytes()).unwrap();
    stream.flush().unwrap();
}
</code></pre>
<p>This is very similar to the 
<a href="https://doc.rust-lang.org/book/ch20-02-multithreaded.html#simulating-a-slow-request-in-the-current-server-implementation">simulation of a slow request</a>
from the Book, but with one important difference:
we're using the non-blocking function <code>async_std::task::sleep</code> instead of the blocking function <code>std::thread::sleep</code>.
It's important to remember that even if a piece of code is run within an <code>async fn</code> and <code>await</code>ed, it may still block.
To test whether our server handles connections concurrently, we'll need to ensure that <code>handle_connection</code> is non-blocking.</p>
<p class="cn">
这和书中<a href="https://doc.rust-lang.org/book/ch20-02-multithreaded.html#simulating-a-slow-request-in-the-current-server-implementation">simulation of a slow request</a>十分相似，但有一点重要的不同：
我们使用的是非阻塞函数`async_std::task::sleep`，而不是阻塞函数`std::thread::sleep`。
重要的是要记住，即使一段代码在“async fn”和`await`中运行，它仍然可能阻塞。
为了测试服务器是否同时处理连接，我们需要确保`handle_connection`是非阻塞的。
</p>
<p>If you run the server, you'll see that a request to <code>127.0.0.1:7878/sleep</code>
will block any other incoming requests for 5 seconds!
This is because there are no other concurrent tasks that can make progress
while we are <code>await</code>ing the result of <code>handle_connection</code>.
In the next section, we'll see how to use async code to handle connections concurrently.</p>
<p class="cn">
如果您运行服务器，您将看到对“127.0.0.1:7878/sleep”的请求将阻止任何其他传入请求5秒钟！
这是因为当我们`await`等待`handle_connection`的结果时，没有其他并发任务可以取得进展。
在下一节中，我们将看到如何使用异步代码并发处理连接。
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="handling-connections-concurrently并发地处理连接"><a class="header" href="#handling-connections-concurrently并发地处理连接">Handling Connections Concurrently(并发地处理连接)</a></h1>
<p>The problem with our code so far is that <code>listener.incoming()</code> is a blocking iterator.
The executor can't run other futures while <code>listener</code> waits on incoming connections,
and we can't handle a new connection until we're done with the previous one.</p>
<p class="cn">
到目前为止，我们的代码存在的问题是`listener.incoming()`是一个阻塞迭代器。
`listener`等待传入连接时，执行器无法运行其他future，
在完成前一个连接之前，我们无法处理新连接。
</p>
<p>In order to fix this, we'll transform <code>listener.incoming()</code> from a blocking Iterator
to a non-blocking Stream. Streams are similar to Iterators, but can be consumed asynchronously.
For more information, see the <a href="09_example/../05_streams/01_chapter.html">chapter on Streams</a>.</p>
<p class="cn">
为了解决这个问题，我们将转换`listener.incoming()`从阻塞迭代器到非阻塞流。
流与迭代器类似，但可以异步使用。
有关更多信息，可以看<a href="09_example/../05_streams/01_chapter.html">Streams章节</a>
</p>
<p>Let's replace our blocking <code>std::net::TcpListener</code> with the non-blocking <code>async_std::net::TcpListener</code>,
and update our connection handler to accept an <code>async_std::net::TcpStream</code>:</p>
<p class="cn">
让我们将阻塞的 `std::net::TcpListener`替换为非阻塞的`async_std::net::TcpListener`，
并更新连接处理程序以接受`async_std::net::TcpStream`：
</p>
<pre><code class="language-rust ignore">use async_std::prelude::*;

async fn handle_connection(mut stream: TcpStream) {
    let mut buffer = [0; 1024];
    stream.read(&amp;mut buffer).await.unwrap();

    //&lt;-- snip --&gt;
    stream.write(response.as_bytes()).await.unwrap();
    stream.flush().await.unwrap();
}
</code></pre>
<p>The asynchronous version of <code>TcpListener</code> implements the <code>Stream</code> trait for <code>listener.incoming()</code>,
a change which provides two benefits.
The first is that <code>listener.incoming()</code> no longer blocks the executor.
The executor can now yield to other pending futures 
while there are no incoming TCP connections to be processed.</p>
<p class="cn">
异步版本的`TcpListener`为`listener.incoming()`实现了`Stream`特性，这一更改提供了两个好处。
第一个是`listener.incoming()` 不再阻塞执行器。
当没有要处理的传入TCP连接时，执行器现在可以向其他挂起的future让步。
</p>
<p>The second benefit is that elements from the Stream can optionally be processed concurrently,
using a Stream's <code>for_each_concurrent</code> method.
Here, we'll take advantage of this method to handle each incoming request concurrently.
We'll need to import the <code>Stream</code> trait from the <code>futures</code> crate, so our Cargo.toml now looks like this:</p>
<p class="cn">
第二个好处是，可以选择使用流的`for_each_concurrent`方法并发处理流中的元素。
这里，我们将利用此方法并发处理每个传入请求。
我们需要从`futures`板条箱中导入`Stream`特性，修改我们Cargo.toml看起来像这样：
</p>
<pre><code class="language-diff">+[dependencies]
+futures = &quot;0.3&quot;

 [dependencies.async-std]
 version = &quot;1.6&quot;
 features = [&quot;attributes&quot;]
</code></pre>
<p>Now, we can handle each connection concurrently by passing <code>handle_connection</code> in through a closure function.
The closure function takes ownership of each <code>TcpStream</code>, and is run as soon as a new <code>TcpStream</code> becomes available.
As long as <code>handle_connection</code> does not block, a slow request will no longer prevent other requests from completing.</p>
<p class="cn">
现在，我们可以通过闭包函数传入`handle_connection`来并发处理每个连接。
闭包函数拥有每个`TcpStream`的所有权，并在新的`TcpStream`可用时立即运行。
只要`handle_connection`没有阻塞，一个缓慢的请求将不再阻止其他请求完成。
</p>
<pre><code class="language-rust ignore">use async_std::net::TcpListener;
use async_std::net::TcpStream;
use futures::stream::StreamExt;

#[async_std::main]
async fn main() {
    let listener = TcpListener::bind(&quot;127.0.0.1:7878&quot;).await.unwrap();
    listener
        .incoming()
        .for_each_concurrent(/* limit */ None, |tcpstream| async move {
            let tcpstream = tcpstream.unwrap();
            handle_connection(tcpstream).await;
        })
        .await;
}
</code></pre>
<h1 id="serving-requests-in-parallel并行服务请求"><a class="header" href="#serving-requests-in-parallel并行服务请求">Serving Requests in Parallel(并行服务请求)</a></h1>
<p>Our example so far has largely presented concurrency (using async code)
as an alternative to parallelism (using threads).
However, async code and threads are not mutually exclusive.
In our example, <code>for_each_concurrent</code> processes each connection concurrently, but on the same thread.
The <code>async-std</code> crate allows us to spawn tasks onto separate threads as well.
Because <code>handle_connection</code> is both <code>Send</code> and non-blocking, it's safe to use with <code>async_std::task::spawn</code>.
Here's what that would look like:</p>
<p class="cn">
到目前为止，我们的示例在很大程度上提供了并发（使用异步代码）作为并行（使用线程）的替代方案。
然而，异步代码和线程并不是互斥的。
在我们的示例中，`for_each_concurrent`并发处理每个连接，但在同一线程上。
`async-std`板条箱也允许我们将任务派生到单独的线程上。
因为`handle_connection`既是可`Send`的又是非阻塞的，所以与 `async_std::task::spawn`一起使用是安全的。
下面是它的样子：
</p>
<pre><pre class="playground"><code class="language-rust">use async_std::task::spawn;

#[async_std::main]
async fn main() {
    let listener = TcpListener::bind(&quot;127.0.0.1:7878&quot;).await.unwrap();
    listener
        .incoming()
        .for_each_concurrent(/* limit */ None, |stream| async move {
            let stream = stream.unwrap();
            spawn(handle_connection(stream));
        })
        .await;
}
</code></pre></pre>
<p>Now we are using both concurrency and parallelism to handle multiple requests at the same time!
See the <a href="09_example/../08_ecosystem/00_chapter.html#single-threading-vs-multithreading">section on multithreaded executors</a>
for more information.</p>
<p class="cn">
现在，我们同时使用并发性和并行性来处理多个请求！
请参考<a href="09_example/../08_ecosystem/00_chapter.html#single-threading-vs-multithreading">多线程执行器</a>获取更多信息
</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-the-tcp-server测试tcp服务器"><a class="header" href="#testing-the-tcp-server测试tcp服务器">Testing the TCP Server(测试TCP服务器)</a></h1>
<p>Let's move on to testing our <code>handle_connection</code> function.</p>
<p class="cn">
让我们继续测试`handle_connection`函数。
</p>
<p>First, we need a <code>TcpStream</code> to work with.
In an end-to-end or integration test, we might want to make a real TCP connection
to test our code.
One strategy for doing this is to start a listener on <code>localhost</code> port 0.
Port 0 isn't a valid UNIX port, but it'll work for testing.
The operating system will pick an open TCP port for us.</p>
<p class="cn">
首先，我们需要一个`TcpStream`来配合。
在端到端或集成测试中，我们可能希望建立真正的TCP连接来测试代码。
执行此操作的一种策略是在`localhost`端口0上启动侦听器。
端口0不是有效的UNIX端口，但可用于测试。
操作系统将为我们选择一个打开的TCP端口。
</p>
<p>Instead, in this example we'll write a unit test for the connection handler,
to check that the correct responses are returned for the respective inputs.
To keep our unit test isolated and deterministic, we'll replace the <code>TcpStream</code> with a mock.</p>
<p class="cn">
相反，在本例中，我们将为连接处理程序编写一个单元测试，以检查是否为各个输入返回了正确的响应。
为了保持单元测试的独立性和确定性，我们将用Mock替换`TcpStream`。
</p>
<p>First, we'll change the signature of <code>handle_connection</code> to make it easier to test.
<code>handle_connection</code> doesn't actually require an <code>async_std::net::TcpStream</code>;
it requires any struct that implements <code>async_std::io::Read</code>, <code>async_std::io::Write</code>, and <code>marker::Unpin</code>.
Changing the type signature to reflect this allows us to pass a mock for testing.</p>
<p class="cn">
首先，我们将更改`handle_connection`的签名，以便于测试。
`handle_connection`实际上并不需要`async_std::net::TcpStream`；
它需要实现`async_std::io::Read`, `async_std::io::Write`和`marker::Unpin`的任何结构。
更改类型签名以反映这一点允许我们通过模拟进行测试。
</p>
<pre><code class="language-rust ignore">use std::marker::Unpin;
use async_std::io::{Read, Write};

async fn handle_connection(mut stream: impl Read + Write + Unpin) {
</code></pre>
<p>Next, let's build a mock <code>TcpStream</code> that implements these traits.
First, let's implement the <code>Read</code> trait, with one method, <code>poll_read</code>.
Our mock <code>TcpStream</code> will contain some data that is copied into the read buffer,
and we'll return <code>Poll::Ready</code> to signify that the read is complete.</p>
<p class="cn">
接下来，让我们构建一个实现这些特性的Mock `TcpStream`。
首先，让我们用一个方法`poll_read`来实现`Read`特征。
我们的模拟`TcpStream`将包含一些复制到读取缓冲区的数据，我们将返回`Poll::Ready`以表示读取完成。
</p>
<pre><code class="language-rust ignore">    use super::*;
    use futures::io::Error;
    use futures::task::{Context, Poll};

    use std::cmp::min;
    use std::pin::Pin;

    struct MockTcpStream {
        read_data: Vec&lt;u8&gt;,
        write_data: Vec&lt;u8&gt;,
    }

    impl Read for MockTcpStream {
        fn poll_read(
            self: Pin&lt;&amp;mut Self&gt;,
            _: &amp;mut Context,
            buf: &amp;mut [u8],
        ) -&gt; Poll&lt;Result&lt;usize, Error&gt;&gt; {
            let size: usize = min(self.read_data.len(), buf.len());
            buf[..size].copy_from_slice(&amp;self.read_data[..size]);
            Poll::Ready(Ok(size))
        }
    }
</code></pre>
<p>Our implementation of <code>Write</code> is very similar,
although we'll need to write three methods: <code>poll_write</code>, <code>poll_flush</code>, and <code>poll_close</code>.
<code>poll_write</code> will copy any input data into the mock <code>TcpStream</code>, and return <code>Poll::Ready</code> when complete.
No work needs to be done to flush or close the mock <code>TcpStream</code>, so <code>poll_flush</code> and <code>poll_close</code>
can just return <code>Poll::Ready</code>.</p>
<p class="cn">
实现`Write`非常相似，虽然我们需要编写三个方法：`poll_write`, `poll_flush`和`poll_close`。
`poll_write`将把所有输入数据复制到模拟的 `TcpStream`中，完成后返回`Poll::Ready`。
无需执行任何操作即可刷新或关闭模拟的`TcpStream`，因此`poll_flush`和`poll_close`只需返回`Poll::Ready`。
</p>
<pre><code class="language-rust ignore">    impl Write for MockTcpStream {
        fn poll_write(
            mut self: Pin&lt;&amp;mut Self&gt;,
            _: &amp;mut Context,
            buf: &amp;[u8],
        ) -&gt; Poll&lt;Result&lt;usize, Error&gt;&gt; {
            self.write_data = Vec::from(buf);

            Poll::Ready(Ok(buf.len()))
        }

        fn poll_flush(self: Pin&lt;&amp;mut Self&gt;, _: &amp;mut Context) -&gt; Poll&lt;Result&lt;(), Error&gt;&gt; {
            Poll::Ready(Ok(()))
        }

        fn poll_close(self: Pin&lt;&amp;mut Self&gt;, _: &amp;mut Context) -&gt; Poll&lt;Result&lt;(), Error&gt;&gt; {
            Poll::Ready(Ok(()))
        }
    }
</code></pre>
<p>Lastly, our mock will need to implement <code>Unpin</code>, signifying that its location in memory can safely be moved.
For more information on pinning and the <code>Unpin</code> trait, see the <a href="09_example/../04_pinning/01_chapter.html">section on pinning</a>.</p>
<p class="cn">
最后，我们的mock需要实现`Unpin`，这意味着它在内存中的位置可以安全地移动。
有关固定和“Unpin”特性的更多信息，请参阅<a href="09_example/../04\u pinning/01\u chapter.html">[pinning章节]</a>。
</p>
<pre><code class="language-rust ignore">    use std::marker::Unpin;
    impl Unpin for MockTcpStream {}
</code></pre>
<p>Now we're ready to test the <code>handle_connection</code> function.
After setting up the <code>MockTcpStream</code> containing some initial data,
we can run <code>handle_connection</code> using the attribute <code>#[async_std::test]</code>, similarly to how we used <code>#[async_std::main]</code>.
To ensure that <code>handle_connection</code> works as intended, we'll check that the correct data
was written to the <code>MockTcpStream</code> based on its initial contents.</p>
<p class="cn">
现在，我们准备测试`handle_connection`函数。
在设置包含一些初始数据的`MockTcpStream`之后，
我们可以使用属性`#[async_std::test]`运行`handle_connection`，类似于使用`#[async_std::main]`的方式。
为了确保`handle_connection`按预期工作，我们将检查是否根据`MockTcpStream`的初始内容将正确的数据写入其中。
</p>
<pre><code class="language-rust ignore">    use std::fs;

    #[async_std::test]
    async fn test_handle_connection() {
        let input_bytes = b&quot;GET / HTTP/1.1\r\n&quot;;
        let mut contents = vec![0u8; 1024];
        contents[..input_bytes.len()].clone_from_slice(input_bytes);
        let mut stream = MockTcpStream {
            read_data: contents,
            write_data: Vec::new(),
        };

        handle_connection(&amp;mut stream).await;
        let mut buf = [0u8; 1024];
        stream.read(&amp;mut buf).await.unwrap();

        let expected_contents = fs::read_to_string(&quot;hello.html&quot;).unwrap();
        let expected_response = format!(&quot;HTTP/1.1 200 OK\r\n\r\n{}&quot;, expected_contents);
        assert!(stream.write_data.starts_with(expected_response.as_bytes()));
    }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="appendix--translations-of-the-book附录本书的翻译版本"><a class="header" href="#appendix--translations-of-the-book附录本书的翻译版本">Appendix : Translations of the Book(附录：本书的翻译版本)</a></h1>
<p>For resources in languages other than English.</p>
<p class="cn">
非英文版本的资源。
</p>
<ul>
<li><a href="https://doc.rust-lang.ru/async-book/">Русский</a></li>
<li><a href="https://jimskapt.github.io/async-book-fr/">Français</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="assets/translate.js"></script>

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
